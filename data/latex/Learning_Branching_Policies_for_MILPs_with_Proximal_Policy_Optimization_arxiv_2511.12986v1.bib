
@InProceedings{balcan18a,
  title = 	 {Learning to Branch},
  author =       {Balcan, Maria-Florina and Dick, Travis and Sandholm, Tuomas and Vitercik, Ellen},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {344--353},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/balcan18a/balcan18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/balcan18a.html},
  abstract = 	 {Tree search algorithms, such as branch-and-bound, are the most widely used tools for solving combinatorial problems. These algorithms recursively partition the search space to find an optimal solution. To keep the tree small, it is crucial to carefully decide, when expanding a tree node, which variable to branch on at that node to partition the remaining space. Many partitioning techniques have been proposed, but no theory describes which is optimal. We show how to use machine learning to determine an optimal weighting of any set of partitioning procedures for the instance distribution at hand using samples. Via theory and experiments, we show that learning to branch is both practical and hugely beneficial.}
}

@article{land1960,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/1910129},
 abstract = {In the classical linear programming problem the behaviour of continuous, nonnegative variables subject to a system of linear inequalities is investigated. One possible generalization of this problem is to relax the continuity condition the variables. This paper presents a simple numerical algorithm for the solution of programming problems in which some or all of the variables can take only discrete values. The algorithm requires no special techniques beyond these used in ordinary linear programming, and lends itself to automatic computing. Its use is illustrated on two numerical examples.},
 author = {A. H. Land and A. G. Doig},
 journal = {Econometrica},
 number = {3},
 pages = {497--520},
 publisher = {[Wiley, Econometric Society]},
 title = {An Automatic Method of Solving Discrete Programming Problems},
 urldate = {2025-07-25},
 volume = {28},
 year = {1960}
}



@InProceedings{brown20a,
  title = 	 {Safe Imitation Learning via Fast {B}ayesian Reward Inference from Preferences},
  author =       {Brown, Daniel and Coleman, Russell and Srinivasan, Ravi and Niekum, Scott},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {1165--1177},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/brown20a/brown20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/brown20a.html},
  abstract = 	 {Bayesian reward learning from demonstrations enables rigorous safety and uncertainty analysis when performing imitation learning. However, Bayesian reward learning methods are typically computationally intractable for complex control problems. We propose Bayesian Reward Extrapolation (Bayesian REX), a highly efficient Bayesian reward learning algorithm that scales to high-dimensional imitation learning problems by pre-training a low-dimensional feature encoding via self-supervised tasks and then leveraging preferences over demonstrations to perform fast Bayesian inference. Bayesian REX can learn to play Atari games from demonstrations, without access to the game score and can generate 100,000 samples from the posterior over reward functions in only 5 minutes on a personal laptop. Bayesian REX also results in imitation learning performance that is competitive with or better than state-of-the-art methods that only learn point estimates of the reward function. Finally, Bayesian REX enables efficient high-confidence policy evaluation without having access to samples of the reward function. These high-confidence performance bounds can be used to rank the performance and risk of a variety of evaluation policies and provide a way to detect reward hacking behaviors.}
}

@inproceedings{brown2020,
 author = {Brown, Daniel and Niekum, Scott and Petrik, Marek},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {2479--2491},
 publisher = {Curran Associates, Inc.},
 title = {Bayesian Robust Optimization for Imitation Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1a669e81c8093745261889539694be7f-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{gupta2020,
 author = {Gupta, Prateek and Gasse, Maxime and Khalil, Elias and Mudigonda, Pawan and Lodi, Andrea and Bengio, Yoshua},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {18087--18097},
 publisher = {Curran Associates, Inc.},
 title = {Hybrid Models for Learning to Branch},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/d1e946f4e67db4b362ad23818a6fb78a-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{he2014,
 author = {He, He and Daum\'{e}, Hal and Eisner, Jason},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning to Search in Branch and Bound Algorithms},
 url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/533d190f5aa2926b2a8a30c8bea0e05d-Paper.pdf},
 volume = {27},
 year = {2014}
}

@inproceedings{wonseok2018,
 author = {Jeon, Wonseok and Seo, Seokin and Kim, Kee-Eung},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {A Bayesian Approach to Generative Adversarial Imitation Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/943aa0fcda4ee2901a7de9321663b114-Paper.pdf},
 volume = {31},
 year = {2018}
}

@article{khalil2016, 
    title={Learning to Branch in Mixed Integer Programming}, volume={30}, url={https://ojs.aaai.org/index.php/AAAI/article/view/10080}, DOI={10.1609/aaai.v30i1.10080}, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Khalil, Elias and Le Bodic, Pierre and Song, Le and Nemhauser, George and Dilkina, Bistra}, year={2016}, month={Feb.} }

@INPROCEEDINGS{ollis2007,
  author={Ollis, Mark and Huang, Wesley H. and Happold, Michael},
  booktitle={2007 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={A Bayesian approach to imitation learning for robot navigation}, 
  year={2007},
  volume={},
  number={},
  pages={709-714},
  keywords={Bayesian methods;Navigation;Robot sensing systems;Costs;Humans;Laser radar;Robot vision systems;Mobile robots;Intelligent robots;Learning systems},
  doi={10.1109/IROS.2007.4399220}}

@article{parsonson2023, title={Reinforcement Learning for Branch-and-Bound Optimisation Using Retrospective Trajectories}, volume={37}, url={https://ojs.aaai.org/index.php/AAAI/article/view/25521}, DOI={10.1609/aaai.v37i4.25521}, number={4}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Parsonson, Christopher W. F. and Laterre, Alexandre and Barrett, Thomas D.}, year={2023}, month={Jun.}, pages={4061-4069} }

@article{wang2025,
title = {Empowering branch-and-bound algorithms via reinforcement and imitation learning for enhanced search},
journal = {Applied Soft Computing},
volume = {170},
pages = {112690},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.112690},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625000018},
author = {Qi Wang},
keywords = {Combinatorial optimization, Branch-and-bound, Deep reinforcement learning, Generative adversarial imitation learning}
}

@article{zarpellon2021, title={Parameterizing Branch-and-Bound Search Trees to Learn Branching Policies}, volume={35}, url={https://ojs.aaai.org/index.php/AAAI/article/view/16512}, DOI={10.1609/aaai.v35i5.16512}, number={5}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Zarpellon, Giulia and Jo, Jason and Lodi, Andrea and Bengio, Yoshua}, year={2021}, month={May}, pages={3931-3939} }

@inproceedings{
zhang2024,
title={Towards Imitation Learning to Branch for {MIP}: A Hybrid Reinforcement Learning based Sample Augmentation Approach},
author={Changwen Zhang and Wenli Ouyang and Hao Yuan and Liming Gong and Yong Sun and Ziao Guo and Zhichen Dong and Junchi Yan},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=NdcQQ82mfy}
}


@Article{Kaan2021,
AUTHOR = {Yilmaz, Kaan and Yorke-Smith, Neil},
TITLE = {A Study of Learning Search Approximation in Mixed Integer Branch and Bound: Node Selection in SCIP},
JOURNAL = {AI},
VOLUME = {2},
YEAR = {2021},
NUMBER = {2},
PAGES = {150--178},
URL = {https://www.mdpi.com/2673-2688/2/2/10},
ISSN = {2673-2688},
DOI = {10.3390/ai2020010}
}

@inproceedings{gasse2019,
 author = {Gasse, Maxime and Chetelat, Didier and Ferroni, Nicola and Charlin, Laurent and Lodi, Andrea},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Exact Combinatorial Optimization with Graph Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/d14c2267d848abeb81fd590f371d39bd-Paper.pdf},
 volume = {32},
 year = {2019}
}

@article{mazyavkina2021,
title = {Reinforcement learning for combinatorial optimization: A survey},
journal = {Computers & Operations Research},
volume = {134},
pages = {105400},
year = {2021},
issn = {0305-0548},
doi = {https://doi.org/10.1016/j.cor.2021.105400},
url = {https://www.sciencedirect.com/science/article/pii/S0305054821001660},
author = {Nina Mazyavkina and Sergey Sviridov and Sergei Ivanov and Evgeny Burnaev},
keywords = {Reinforcement learning, Operations research, Combinatorial optimization, Value-based methods, Policy-based methods}
}


@InProceedings{andino2021a,
  title = 	 {Unitary Branching Programs: Learnability and Lower Bounds},
  author =       {Andino, Fidel Ernesto Diaz and Kokkou, Maria and De Oliveira Oliveira, Mateus and Vadiee, Farhad},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {297--306},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/andino21a/andino21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/andino21a.html}
}

@inproceedings{ho2016,
 author = {Ho, Jonathan and Ermon, Stefano},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Generative Adversarial Imitation Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2016/file/cc7e2b878868cbae992d1fb743995d8f-Paper.pdf},
 volume = {29},
 year = {2016}
}

@article{choi2021,
title = {TrajGAIL: Generating urban vehicle trajectories using generative adversarial imitation learning},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {128},
pages = {103091},
year = {2021},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2021.103091},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X21001121},
author = {Seongjin Choi and Jiwon Kim and Hwasoo Yeo},
keywords = {Urban vehicle trajectories, Trajectory data analysis, Trajectory data generation, Generative model, Generative adversarial imitation learning}
}

@misc{timothy2019,
      title={Continuous control with deep reinforcement learning}, 
      author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
      year={2019},
      eprint={1509.02971},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1509.02971}, 
}

@ARTICLE{jospin2022,
  author={Jospin, Laurent Valentin and Laga, Hamid and Boussaid, Farid and Buntine, Wray and Bennamoun, Mohammed},
  journal={IEEE Computational Intelligence Magazine}, 
  title={Hands-On Bayesian Neural Networks—A Tutorial for Deep Learning Users}, 
  year={2022},
  volume={17},
  number={2},
  pages={29-48},
  keywords={Deep learning;Training data;Uncertainty;Design methodology;Computational modeling;Stochastic processes;Bayes methods;Neural networks;Tutorials},
  doi={10.1109/MCI.2022.3155327}}


@article{lin2022,
	title = {Learning to branch with {Tree}-aware {Branching} {Transformers}},
	volume = {252},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705122007298},
	doi = {https://doi.org/10.1016/j.knosys.2022.109455},
	journal = {Knowledge-Based Systems},
	author = {Lin, Jiacheng and Zhu, Jialin and Wang, Huangang and Zhang, Tao},
	year = {2022},
	keywords = {Branch and Bound, Branching strategies, Machine learning, Mixed Integer Linear Programming},
	pages = {109455},
}

@incollection{matai2010,
  author = {Rajesh Matai and Surya Prakash Singh and Murari Lal Mittal},
  title = {Traveling Salesman Problem: An Overview of Applications, Formulations, and Solution Approaches},
  booktitle = {Traveling Salesman Problem},
  editor = {Donald Davendra},
  chapter = {1},
  publisher = {IntechOpen},
  year = {2010},
  address = {Rijeka},
  url = {https://doi.org/10.5772/12909}
}


@article{ren2010,
	title = {A {MILP} model for integrated plan and evaluation of distributed energy systems},
	volume = {87},
	issn = {0306-2619},
	url = {https://www.sciencedirect.com/science/article/pii/S0306261909004152},doi = {https://doi.org/10.1016/j.apenergy.2009.09.023},
	number = {3},
	journal = {Applied Energy},
	author = {Ren, Hongbo and Gao, Weijun},
	year = {2010},
	keywords = {Distributed energy resources, Economic effect, Energetic and environmental effects, MILP model, Plan and evaluation, Sensitivity analysis},
	pages = {1001--1014},
}

@Inbook{land2010,
author="Land, Ailsa H.
and Doig, Alison G.",
editor="J{\"u}nger, Michael
and Liebling, Thomas M.
and Naddef, Denis
and Nemhauser, George L.
and Pulleyblank, William R.
and Reinelt, Gerhard
and Rinaldi, Giovanni
and Wolsey, Laurence A.",
title="An Automatic Method for Solving Discrete Programming Problems",
bookTitle="50 Years of Integer Programming 1958-2008: From the Early Years to the State-of-the-Art",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="105--132",
isbn="978-3-540-68279-0",
doi="10.1007/978-3-540-68279-0_5",
url="https://doi.org/10.1007/978-3-540-68279-0_5"
}

@inproceedings{scavuzzo2022,
 author = {Scavuzzo, Lara and Chen, Feng and Chetelat, Didier and Gasse, Maxime and Lodi, Andrea and Yorke-Smith, Neil and Aardal, Karen},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {18514--18526},
 publisher = {Curran Associates, Inc.},
 title = {Learning to Branch with Tree MDPs},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/756d74cd58592849c904421e3b2ec7a4-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@inproceedings{Wenhan2023,
  author={Wang, Wenhan and Zhang, Kechi and Li, Ge and Liu, Shangqing and Li, Anran and Jin, Zhi and Liu, Yang},
  booktitle={2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Learning Program Representations with a Tree-Structured Transformer}, 
  year={2023},
  volume={},
  number={},
  pages={248-259},
  keywords={Representation learning;Location awareness;Deep learning;Source coding;Neural networks;Computer bugs;Syntactics;AI for SE;program representation learning},
  doi={10.1109/SANER56733.2023.00032}}

@inproceedings{zhang2022,
  author={Zhang, Tianyu and Banitalebi-Dehkordi, Amin and Zhang, Yong},
  booktitle={2022 26th International Conference on Pattern Recognition (ICPR)}, 
  title={Deep Reinforcement Learning for Exact Combinatorial Optimization: Learning to Branch}, 
  year={2022},
  volume={},
  number={},
  pages={3105-3111},
  keywords={Deep learning;Systematics;Monte Carlo methods;NP-hard problem;Input variables;Reinforcement learning;Pattern recognition},
  doi={10.1109/ICPR56361.2022.9956256}}

@article{ahluwalia2021,
title = {Policy-based branch-and-bound for infinite-horizon Multi-model Markov decision processes},
journal = {Computers & Operations Research},
volume = {126},
pages = {105108},
year = {2021},
issn = {0305-0548},
doi = {https://doi.org/10.1016/j.cor.2020.105108},
url = {https://www.sciencedirect.com/science/article/pii/S0305054820302252},
author = {Vinayak S. Ahluwalia and Lauren N. Steimle and Brian T. Denton},
keywords = {Markov decision processes, Parameter uncertainty, Branch-and-bound},
abstract = {Markov decision processes (MDPs) are models for sequential decision-making that inform decision making in many fields, including healthcare, manufacturing, and others. However, the optimal policy for an MDP may be sensitive to the reward and transition parameters which are often uncertain because parameters are typically estimated from data or rely on expert opinion. To address parameter uncertainty in MDPs, it has been proposed that multiple models of the parameters be incorporated into the solution process, but solving these problems can be computationally challenging. In this article, we propose a policy-based branch-and-bound approach that leverages the structure of these problems and numerically compare several important algorithmic designs. We demonstrate that our approach outperforms existing methods on test cases from the literature including randomly generated MDPs, a machine maintenance MDP, and an MDP for medical decision making.}
}

@inproceedings{
zhang2025learning,
title={Learning to Select Nodes in Branch and Bound with Sufficient Tree Representation},
author={Sijia Zhang and Shuli Zeng and Shaoang Li and Feng Wu and Xiangyang Li},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=gyvYKLEm8t}
}

@article{Feng_Yang_2025, title={SORREL: Suboptimal-Demonstration-Guided Reinforcement Learning for Learning to Branch}, volume={39}, url={https://ojs.aaai.org/index.php/AAAI/article/view/33219}, DOI={10.1609/aaai.v39i11.33219}, abstractNote={Mixed Integer Linear Program (MILP) solvers are mostly built upon a Branch-and-Bound (B&amp;B) algorithm, where the efficiency of traditional solvers heavily depends on hand-crafted heuristics for branching. The past few years have witnessed the increasing popularity of data-driven approaches to automatically learn these heuristics. However, the success of these methods is highly dependent on the availability of high-quality demonstrations, which requires either the development of near-optimal heuristics or a time-consuming sampling process. This paper averts this challenge by proposing Suboptimal-Demonstration-Guided Reinforcement Learning (SORREL) for learning to branch. SORREL selectively learns from suboptimal demonstrations based on value estimation. It utilizes suboptimal demonstrations through both offline reinforcement learning on the demonstrations generated by suboptimal heuristics and self-imitation learning on past good experiences sampled by itself. Our experiments demonstrate its advanced performance in both branching quality and training efficiency over previous methods for various MILPs.}, number={11}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Feng, Shengyu and Yang, Yiming}, year={2025}, month={Apr.}, pages={11212-11220} }

@article{qu2022,
  author       = {Qingyu Qu and
                  Xijun Li and
                  Yunfan Zhou and
                  Jia Zeng and
                  Mingxuan Yuan and
                  Jie Wang and
                  Jinhu Lv and
                  Kexin Liu and
                  Kun Mao},
  title        = {An Improved Reinforcement Learning Algorithm for Learning to Branch},
  journal      = {CoRR},
  volume       = {abs/2201.06213},
  year         = {2022},
  url          = {https://arxiv.org/abs/2201.06213},
  eprinttype    = {arXiv},
  eprint       = {2201.06213},
  timestamp    = {Tue, 08 Apr 2025 16:48:08 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2201-06213.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{prajadis2021,
author="Parjadis, Augustin
and Cappart, Quentin
and Rousseau, Louis-Martin
and Bergman, David",
editor="Stuckey, Peter J.",
title="Improving Branch-and-Bound Using Decision Diagrams and Reinforcement Learning",
booktitle="Integration of Constraint Programming, Artificial Intelligence, and Operations Research",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="446--455",
abstract="Combinatorial optimization has found applications in numerous fields, from transportation to scheduling and planning. The goal is to find an optimal solution among a finite set of possibilities. Most exact approaches use relaxations to derive bounds on the objective function, which are embedded within a branch-and-bound algorithm. Decision diagrams provide a new approach for obtaining bounds that, in some cases, can be significantly better than those obtained with a standard linear programming relaxation. However, it is known that the quality of the bounds achieved through this bounding method depends on the ordering of variables considered for building the diagram. Recently, a deep reinforcement learning approach was proposed to compute a high-quality variable ordering. The bounds obtained exhibited improvements, but the mechanism proposed was not embedded in a branch-and-bound solver. This paper proposes to integrate learned optimization bounds inside a branch-and-bound solver, through the combination of reinforcement learning and decision diagrams. The results obtained show that the bounds can reduce the tree search size by a factor of at least three on the maximum independent set problem.",
isbn="978-3-030-78230-6"
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@article{akiba2019,
  author       = {Takuya Akiba and
                  Shotaro Sano and
                  Toshihiko Yanase and
                  Takeru Ohta and
                  Masanori Koyama},
  title        = {Optuna: {A} Next-generation Hyperparameter Optimization Framework},
  journal      = {CoRR},
  volume       = {abs/1907.10902},
  year         = {2019},
  url          = {http://arxiv.org/abs/1907.10902},
  eprinttype    = {arXiv},
  eprint       = {1907.10902},
  timestamp    = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1907-10902.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@book{scip,
title = "The SCIP Optimization Suite 6.0",
abstract = "The SCIP Optimization Suite provides a collection of software packages for mathematical optimization centered around the constraint integer programming framework SCIP. This paper discusses enhancements and extensions contained in version 6.0 of the SCIP Optimization Suite. Besides performance improvements of the MIP and MINLP core achieved by new primal heuristics and a new selection criterion for cutting planes, one focus of this release are decomposition algorithms. Both SCIP and the automatic decomposition solver GCG now include advanced functionality for performing Benders{\textquoteright} decomposition in a generic framework. GCG{\textquoteright}s detection loop for structured matrices and the coordination of pricing routines for Dantzig-Wolfe decomposition has been significantly revised for greater flexibility. Two SCIP extensions have been added to solve the recursive circle packing problem by a problem-specific column generation scheme and to demonstrate the use of the new Benders{\textquoteright} framework for stochastic capacitated facility location. Last, not least, the report presents updates and additions to the other components and extensions of the SCIP Optimization Suite: the LP solver SoPlex, the modeling language Zimpl, the parallelization framework UG, the Steiner tree solver SCIP-Jack, and the mixed-integer semidefinite programming solver SCIP-SDP.",
author = "Ambros Gleixner and Michael Bastubbe and Leon Eifler and Tristan Gally and Gottwald, \{Robert Lion\} and Gregor Hendel and Christopher Hojny and Thorsten Koch and L{\"u}bbecke, \{Marco E.\} and Maher, \{Stephen J.\} and Matthias Miltenberger and Benjamin M{\"u}ller and Pfetsch, \{Marc E.\} and Christian Puchert and Daniel Rehfeldt and Franziska Schl{\"o}sser and Christoph Schubert and Felipe Serrano and Yuji Shinano and Viernickel, \{Jan Merlin\} and Matthias Walter and Fabian Wegscheider and Witt, \{Jonas T.\} and Jakob Witzig",
year = "2018",
language = "English",
series = "ZIB Report",
publisher = "Zuse Institut Berlin",
}

@InProceedings{maher2016,
author="Maher, Stephen
and Miltenberger, Matthias
and Pedroso, Jo{\~a}o Pedro
and Rehfeldt, Daniel
and Schwarz, Robert
and Serrano, Felipe",
editor="Greuel, Gert-Martin
and Koch, Thorsten
and Paule, Peter
and Sommese, Andrew",
title="PySCIPOpt: Mathematical Programming in Python with the SCIP Optimization Suite",
booktitle="Mathematical Software -- ICMS 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="301--307",
abstract="SCIP is a solver for a wide variety of mathematical optimization problems. It is written in C and extendable due to its plug-in based design. However, dealing with all C specifics when extending SCIP can be detrimental to development and testing of new ideas. This paper attempts to provide a remedy by introducing PySCIPOpt, a Python interface to SCIP that enables users to write new SCIP code entirely in Python. We demonstrate how to intuitively model mixed-integer linear and quadratic optimization problems and moreover provide examples on how new Python plug-ins can be added to SCIP.",
isbn="978-3-319-42432-3"
}


@article{Linderoth1999,
author = {Linderoth, J. T. and Savelsbergh, M. W. P.},
title = {A Computational Study of Search Strategies for Mixed Integer Programming},
journal = {INFORMS Journal on Computing},
volume = {11},
number = {2},
pages = {173-187},
year = {1999},
doi = {10.1287/ijoc.11.2.173},
URL = { 
        https://doi.org/10.1287/ijoc.11.2.173
},
eprint = { 
        https://doi.org/10.1287/ijoc.11.2.173
}
,
    abstract = { The branch-and-bound procedure for solving mixed integer programming (MIP) problems using linear programming relaxations has been used with great success for decades. Over the years, a variety of researchers have studied ways of making the basic algorithm more effective. Breakthroughs in the fields of computer hardware, computer software, and mathematics have led to increasing success at solving larger and larger MIP instances. The goal of this article is to survey many of the results regarding branch-and-bound search strategies and evaluate them again in light of the other advances that have taken place over the years. In addition, novel search strategies are presented and shown to often perform better than those currently used in practice. }
}

@InProceedings{Gamrath2017,
author="Gamrath, Gerald
and Schubert, Christoph",
editor="Kliewer, Natalia
and Ehmke, Jan Fabian
and Bornd{\"o}rfer, Ralf",
title="Measuring the Impact of Branching Rules for Mixed-Integer Programming",
booktitle="Operations Research Proceedings 2017",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="165--170",
abstract="Branching rules are an integral component of the branch-and-bound algorithm typically used to solve mixed-integer programs and subject to intense research. Different approaches for branching are typically compared based on the solving time as well as the size of the branch-and-bound tree needed to prove optimality. The latter, however, has some flaws when it comes to sophisticated branching rules that do not only try to take a good branching decision, but have additional side-effects. We propose a new measure for the quality of a branching rule that distinguishes tree size reductions obtained by better branching decisions from those obtained by such side-effects. It is evaluated for common branching rules providing new insights in the importance of strong branching.",
isbn="978-3-319-89920-6"
}

@inproceedings{Paszke2019,
 author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf},
 volume = {32},
 year = {2019}
}

@book{nemenyi1963distribution,
  title={Distribution-free multiple comparisons.},
  author={Nemenyi, Peter Bjorn},
  year={1963},
  publisher={Princeton University}
}

@article{friedman1937use,
  title={The use of ranks to avoid the assumption of normality implicit in the analysis of variance},
  author={Friedman, Milton},
  journal={Journal of the american statistical association},
  volume={32},
  number={200},
  pages={675--701},
  year={1937},
  publisher={Taylor \& Francis}
}
