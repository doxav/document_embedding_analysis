\documentclass{article}



\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}
\usepackage{enumitem}


\title{Agentic AI Systems in Electrical Power Systems Engineering: Current State-of-the-Art and Challenges}

%\date{September 9, 1985}	% Here you can change the date presented in the paper title
%\date{} 					% Or removing it

\author{ \href{https://orcid.org/0000-0002-6151-8183}{\includegraphics[scale=0.06]{orcid.pdf}\hspace{1mm}Soham Ghosh} \\
    Senior Member, IEEE \\
	Independent Researcher\\
	Overland Park, KS 66211 \\
	\texttt{sghosh27@ieee.org} \\
	%% examples of more authors
	\And
	\href{https://orcid.org/0009-0005-1675-9761}{\includegraphics[scale=0.06]{orcid.pdf}\hspace{1mm}Gaurav Mittal}, \\
    Senior Member, IEEE \\
	Independent Researcher\\
	Overland Park, KS 66211 \\
	\texttt{mittalgaurav@ieee.org} \\
	%% \AND
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
}

% Uncomment to remove the date
%\date{}

% Uncomment to override  the `A preprint' in the header
\renewcommand{\headeright}{Technical Report}
%\renewcommand{\undertitle}{Technical Report}
\renewcommand{\shorttitle}{\textit{Agentic AI} in Electrical Power Systems Engineering}

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
pdftitle={Agentic AI Systems in Electrical Engineering: Current State-of-the-Art and Challenges},
pdfsubject={eess.SY/cs.SY},
pdfauthor={Soham ~Ghosh, Gaurav ~Mittal},
pdfkeywords={Agentic AI, Large Language Model (LLM), Power system automation, Model Context Protocol (MCP), Autonomous agents, Survival analysis, Agentic collusion, Zero trust architecture.},
}

\begin{document}
\maketitle

\begin{abstract}
	Agentic AI systems have recently emerged as a critical and transformative approach in artificial intelligence, offering capabilities that extend far beyond traditional AI agents and contemporary generative AI models. This rapid evolution necessitates a clear conceptual and taxonomical understanding to differentiate this new paradigm. Our paper addresses this gap by providing a comprehensive review that establishes a precise definition and taxonomy for "agentic AI," with the aim of distinguishing it from previous AI paradigms. The concepts are gradually introduced, starting with a highlight of its diverse applications across the broader field of engineering. The paper then presents four detailed, state-of-the-art use case applications specifically within electrical engineering. These case studies demonstrate practical impact, ranging from an advanced agentic framework for streamlining complex power system studies and benchmarking to a novel system developed for survival analysis of dynamic pricing strategies in battery swapping stations. Finally, to ensure robust deployment, the paper provides detailed failure mode investigations. From these findings, we derive actionable recommendations for the design and implementation of safe, reliable, and accountable agentic AI systems, offering a critical resource for researchers and practitioners.
\end{abstract}


% keywords can be removed
\keywords{Agentic AI \and Large Language Model (LLM) \and Power system automation \and Model Context Protocol (MCP) \and Autonomous agents \and Survival analysis \and Agentic collusion \and Zero trust architecture.}


\section{Introduction}
The field of artificial intelligence (AI) is undergoing a significant paradigm shift, moving from systems that passively generate content to more of autonomous systems that can reason and react, play, and act, to achieve complex goals ~\cite{1_murugesan2025rise,2_raheem2025agentic}. The evolution as being witnessed in the US and globally is bound to have profound implications for high-stakes domains such as engineering. The progression of this technological trend can be broadly traced through three key phases: traditional agent-based AI systems, generative AIs, and the recent emergence of agentic AI frameworks.

Historically, the concept of an AI agent has been foundational, and followed a traditional definition of an entity that recognizes its surroundings and acts upon it ~\cite{3_Russell_Norvig_2010}. Early agent-based systems ~\cite{4_calegari2021logic,5_cardoso2021review} focused on coordination and had limited problem-solving capabilities often within the bounds of predefined and narrow operational contexts. While effective for specific tasks like distributed control or optimization, these agents lacked generative reasoning and adaptability to novel problems. The second phase of this evolution was catalyzed by the advent of Large Language Models (LLMs), which underpin Generative AI (GenAI), with GenAI systems like ChatGPT and Gemini demonstrating unprecedented ability to comprehend context and produce multimodal human-like text, codes, and other media. In an engineering context, GenAI served as a powerful assistant, capable of drafting codes, summarizing technical documents, or suggesting initial design parameters. However, GenAI is by its very design ‘reactive’, i.e., it responds to a prompt to complete a discrete task but does not possess its own goals, nor can it independently verify or execute its outputs in a real-world feedback loop, by comprehending a complex goal, dissecting and solving it. 

This is where the current and the third evolutionary phase come into play; the third phase is that of Agentic AI. This represents an evolutionary leap by integrating the reasoning capabilities of LLMs with the classical agent's ability to act. Agentic systems are not merely content generators; they are goal-oriented systems that can autonomously decompose a high-level objective into a sequence of executable sub-tasks. By its design, Agentic AI can plan, memorize, reflect on its performance, and interact with external tools, such as compilers, simulators, or web APIs, to execute its plan and adapt to new information. A seminal study in this area is that of Park et al.~\cite{6_park2023generative}, who introduced the concept of “generative agents” in a simulated environment. These LLM-powered agents exhibited believable emergent social behavior by operating on a "Perceive, Plan, Retrieve, Reflect, and Act" cycle, thereby demonstrating their long-term memory and self-directed activity. This work provided the foundational architecture for more complex agentic systems. Subsequent research has focused on formalizing these architectures, with comprehensive surveys by Wang et al. ~\cite{7_wang2024survey} highlighting the critical components of agentic AI with internal intelligence (reasoning, reflection, memory) and external tool invocation.

In complex engineering workflows, an agentic system can manage the entire process rather than just a single step. For example, in integrated circuit (IC) design, a GenAI model might generate a plausible but unverified block of Verilog code. In contrast, an agentic system can write the code, execute a simulation using an industry-standard tool, parse the resulting log file, identify a timing violation or bug, reflect on the error, modify its original code, and re-run the simulation, iterating until the design specifications are met. This closed-loop feedback mechanism, which mimics the core workflow of a human engineer, has already been demonstrated in recent studies such as ASIC-Agent (2024) and Agentic-HLS (2024) ~\cite{8_oztas2024agentic}, which apply agentic reasoning to full ASIC generation and high-level synthesis, respectively. It is under this context that we present subsection I.A to discuss the potential of agentic AI as a transformative technology in engineering design and applications, and subsection I.B to illustrate the manuscript contribution and structure.

\subsection{Manuscript contributions and structure}
This manuscript provides the first comprehensive review of agentic AI systems specifically tailored for the electrical and computer engineering domains. Our primary contribution is to bridge the gap between the theoretical architecture of agentic AI and its state-of-the-art practical application in electrical engineering, while also systematically identifying the domain-specific challenges to its deployment.

The remainder of this paper is structured as follows:
\begin{itemize}
    \item	Section 2 discusses the taxonomical difference between traditional AI agents, Generative AI, and the new paradigm of Agentic AI, establishing a clear conceptual framework. This section also contains illustrative use cases across the broader field of engineering to provide context for an agent-driven transformation of design and operational workflows.
    \item	Section 3 presents a detailed analysis of advanced state-of-the-art applications in the field of electrical engineering, focusing on power systems, smart grids, and semiconductor design. This section also highlights our methodology for shortlisting these cutting-edge use cases.
    \item	Section 4 conducts a critical review of the significant challenges and practical considerations for deploying trustworthy agentic AI in engineering. This includes security risks, such as the adversarial spread of false information and cascading misinformation from LLM rewrites, as well as practical barriers to building trustworthiness, such as model ambiguity, vulnerability to tool injection, and the necessity of robust human-in-the-loop governance. In addition to discussing the problems, we present the state-of-the art mitigation solutions.
    \item	Section 5 concludes the paper, summarizing our findings and outlining key directions for future research.
\end{itemize}

\section{Foundational Theory of Agentic AI and Comparison with AI Agents}
As illustrated in Figure~\ref{fig0}(a), search interest in ‘Agentic AI’ as recorded by Google Trends was virtually nonexistent prior to 2025 and began to gain traction only after the first quarter of 2025. Figure~\ref{fig0}(b) shows the top US metro location linked with the search interest in ‘Agentic AI’. In comparison, search popularity for the keywords ‘AI agents’ and ‘generative AI’ existed for some time (approximately since 2023 to present (2025)), and thus the question arises as to what is the difference between these three apparently similar and distinct paradigms? It is important that formal taxonomical understanding between these three separate areas of artificial intelligence be formed, and such a task has been undertaken in this section. Such formal taxonomical understanding is essential for several different reasons, including:
\begin{itemize}
    \item \textit{Guiding industry and innovation strategies:} Companies and developers need to align their research and development strategies to the right class of technology, as needed based on their particular use case. For example, generative AI companies might pivot towards agentic orchestration only if they understand the fundamental differences and requirements between them.
    \item \textit{Avoiding conceptual ambiguity:} In common media, these terms are often used interchangeably, even though they refer to fundamentally different capabilities:
    \begin{itemize}
        \item Generative AI focuses on content generation based on learned patterns (e.g., text, image, code).
        \item AI agents involve goal-driven entities that can act within predefined boundaries, often automating specific workflows.
        \item Agentic AI introduces a higher level of autonomy, reasoning, planning, and coordination across tools or environments.
    \end{itemize}
    \item \textit{Enabling rigorous research and benchmarking:} Benchmarking of generative AI-based content generation vastly differs from that for multi-step autonomous action. Hence, formal taxonomy provides a structured lens to define the different problem spaces.
\end{itemize}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{fig0.png}
    \caption{Trends in AI paradigms. \textbf{(a)} Google Trend showing 'Agentic AI' trend picking up post Q2 2025 from relative zero interest. \textbf{(b)} Top US metro locations showing popularity with the search term 'Agentic AI' between Oct 2024 through Sep 2025.}
    \label{fig0}
\end{figure*}


Now that we have understood why formal taxonomical classification of these three areas of AI is essential, the focus is now shifted to form a foundational understanding of these three areas.

\subsection{Foundational understanding of AI agents}
AI agents are defined as an autonomous or semi-autonomous computational entity that reasons over information and takes prompt-based actions to achieve generally specific objectives ~\cite{9_acharya2025agentic}. It has a greater degree of adaptability and reasoning as compared to static, predefined sequences of instructions (e.g., shell scripts, Python scripts, macros) that execute exactly as written. They have found application within the domain of customer service ~\cite{10_chaturvedi2023opportunities}, with bots that have the ability to showcase positive sentiment during customer service interactions ~\cite{11_han2023bots} or provide a personal touch and improve the customer experience in customer service ~\cite{12_blumel2024personal}. In industrial domains, multimodal re-trieval-augmented generation agents are increasingly applied to accurately identify, count, and locate objects, particularly within complex scenes containing occlusions or small distracting objects ~\cite{13_xue2024enhanced}, or AI meeting-summarizing agent automating the meeting note-taking process in real time, ensuring that essential discussion contents are precisely captured and accessible for later review and usage ~\cite{14_shcherbakov_2025}.

\subsection{Foundational understanding of generative AI}
Generative AI refers to a class of artificial intelligence systems that are designed to create new content, such as text, images, audio, video, code, or other data, that resembles or extends human-produced work. Generative AI models are trained using large language models (LLMs) or large visual models (LVMs) that learn patterns from massive datasets of text, images, audio, or code. To produce an output, generative AI requires a user prompt (such as zero-shot, few-shot, chain-of-thought, tree-of-thought ~\cite{15_al2025evaluation,16_yao2023tree} and doesn’t operate with autonomous goals. It must be highlighted that the multimodal capacity of generative AI allows systems to capture richer semantic relationships and expand the operational scope of AI systems beyond traditional unimodal applications. Such multimodal capacity is being widely seen in the field of generative AI ~\cite{17_wu2023multimodal,18_guo2022switch} (GPT-4 versus GPT-3, Switch-BERT versus BERT) and is especially powerful in engineering, design, and knowledge-intensive fields.

\subsection{Emergence and foundational understanding of Agentic AI}
So far, we have seen that AI agents performed well-defined tasks in structured environments, tasks such as process automation, customer assistance, etc., while generative AI gained the ability to understand and produce context-aware outputs across modalities (text, image, code, etc.). Agentic AI merges these two ideas, by bringing a higher degree of autonomy and planning (via goal decomposition) along with adaptive, multi-modal reasoning. An agentic AI framework usually consists of an orchestrator, a delegate, and a an ensemble of specialized AI agents, as shown in Figure~\ref{fig1}, with the orchestrator agent analyzing the goal of the overall framework and decomposing the tasks into coarse- or fine-grained smaller decompositions ~\cite{19_gabriel2024advancing}, which are then passed onto the AI agents by the delegator. The delegator consolidates the results of the AI agents once their tasks (or subtasks) are completed and helps the agentic AI framework move towards its goal.

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{Figure_first.png}
    \caption{Overview of the framework for: \textbf{(a)} AI agent \textbf{(b)} Agentic AI system \textbf{(c)} Condensed representation of an agentic AI system.}
    \label{fig1}
\end{figure*}

Table~\ref{tab1} summarizes and further extends this section with a comprehensive set of distinctions between the three AI paradigms, namely agent-based AI, generative AI, and agentic AI.

\begin{table*}
\begin{center}
\caption{Comprehensive distinction between AI agent-based systems (agent-based AI, generative AI, and agentic AI)}
\label{table}
\setlength{\tabcolsep}{3pt}
\begin{tabular}{|p{60pt}|p{75pt}|p{75pt}|p{75pt}|p{130pt}|}
\hline
Distinction \par categories& Dimensions within the \par distinction categories& AI-agent& Generative AI& Agentic AI \\
\hline

{}& Initiation type & Rule-based or event-driven or prompt-driven&Prompt-driven& 
Self-initiating or goal-directed \\

\textbf{System initiation and control}& Autonomy level& Low &
Medium & High. Capable of autonomous planning and execution\\

{}& Task scope& Narrow, predefined &
Broad but single pass & Multi-step, cross-domain workflow\\
\hline

{}& Learning& Minimal &
Learned during pretraining; limited online learning & Online adaptation, reinforcement, and context-aware reasoning\\
\textbf{Interaction and} \par \textbf{coordination}& Coordination strategy& Static protocols and single agent &
Minimal – single-turn interaction & Multi-agent orchestration, negotiation, adaptive coordination\\
{}& Social interaction& Limited &
Human-centric & Multi-agent, human+agent+agent ecosystems\\
{}& Key roles& Prompt driven task execution &
Content generation & Task decomposition, decision-making, dynamic collaboration, goal-based improvements\\
\hline
\textbf{Data and core component}& External data access& Fixed APIs or statis data feeds &
Limited to training data and prompt context & Dynamic access to APIs, tools, knowledge bases, and real-time systems\\
{}& Core component& LLM + tools &
LLM + pattern selection (and no tools) & Multiple LLMs + tools\\
\hline
\textbf{Other examples}& ---& Thermostat controllers &
ChatGPT, Midjourney & Workflow orchestration; example, such as goal-oriented federated learning-based electric grid asset management to improve SAIDI, SAIFI metrics.
\\
\hline
\end{tabular}
\label{tab1}
\end{center}
\end{table*}

\subsection{AI Paradigms and their Broader Applications in the Field of Engineering and Technology Management}
Before introducing domain-specific state-of-the-art use cases of agentic AI in the field of electrical engineering, a review of possible use cases of agentic AI in the broader domains of engineering and technology management should be discussed. From this broader standpoint, Table~\ref{tab2} may help the readers form a deeper understanding of use cases of AI based system. It illustrates the various use cases of these AI-based systems including AI agents, generative AI, and agentic AI systems. 

It is important to note that while AI agents respond to user-generated inquiries and generative AI synthesizes new information, agentic AI systems are usually goal-driven and encompass a complex orchestration of tasks. 

\begin{table*}
\begin{center}
\caption{Summary and comparison of state-of-the-art review papers on AI based systems (agent-based AI, generative AI, and agentic AI) for engineering applications}
\label{table}
\setlength{\tabcolsep}{3pt}
\begin{tabular}{|p{35pt}|p{100pt}|p{130pt}|p{130pt}|}
\hline
Ref \par Year& Engineering domain and agent type& Main points& Shortcomings \\
\hline
~\cite{20_githubPowerWFElectricityMarket}, \par ~\cite{21_zhang2025poweragent} \par (2025)
& Assistant for energy market rules, \par Agent-based AI (RAG)
& RAG based AI agent \textbf{responding} to electricity market \textbf{inquiries} by referencing an internal database of market rules.& Concept could be expanded to contextual or structure-aware RAG for better retrieval performance of tabular or linked data. \\
\hline

~\cite{22_m2024augmenting} \par (2025)
& LLM chemistry agent, \par Generative AI
& Generative AI agent in the field of chemistry designed to successfully \textbf{plan and synthesize} new materials. & Strength of the in-built guardrails to check against controlled chemical and explosive depends on the exhaustive nature of the repositories being used. \\
\hline

~\cite{23_cui2025gencontrol} \par (2025)
& Autonomous design of control algorithms, \par Generative AI
& Using generative AI, successfully \textbf{evolved} a basic controller template into a high-performance controller. & Limited scope for evolution of control algorithms.  \\
\hline
~\cite{24_elrefaie2025ai} \par (2025)
& Automotive engineering, \par Agentic AI
& Robust Agentic AI framework with four AI agents for (a) styling, (b) CAD, (c) meshing, and (d) simulation having a \textbf{goal} to produce sophisticated aesthetic and aerodynamical designs. & Methodology for mesh evaluation remains limited.  \\
\hline
~\cite{25_dev2025advanced} \par (2025)
& 6G wireless network evolution, \par Agentic AI
& Agentic AI framework, designed with a \textbf{goal} to optimize the 6G services, communication, flow of data using context, semantics, and sustainability characteristics thus, realizing the true potential of 6G. & Agentic AI in a 6G framework requires high computation with the framework possibly suffering from latency issues in complex model scenario.  \\
\hline
~\cite{26_khamis2025agentic} \par (2025)
& Effortless vehicular parking, \par Agentic AI
& Agentic AI framework aimed at improving urban mobility in densely populated areas. The agentic AI’s \textbf{goal} is to use cooperative coordination between its agents to provide a frictionless parking experience for the user. & The evaluation is still laboratory-style. Area of improvement would be deployment in an actual urban mobility system or real parking infrastructure. \\
\hline

~\cite{27_tiwari2025conceptualising} \par (2025)
& AI based urban planning, \par Agentic AI
& A fundamental reimagining of urbanism. 
An agentic AI framework that continuously recalibrates its operational priorities based on a set of \textbf{goals} for optimal urban outcomes. & Limited attention has been given to the necessary in-built guardrails that can secure equitable incentive distribution for marginalized urban communities. \\
\hline

~\cite{28_li2024multi} \par (2025)
& Energy markets, \par Agentic AI
& Agentic AI leveraging actor transformer-based critic (ATC) methodology having the \textbf{goal} for profit maximization through autonomous energy bidding and decision making. & A shared transformer encoder used for privacy-preserving purposes. \\
\hline

~\cite{29_guo2024controlagent} \par (2025)
& Control system tuning/ evaluation, \par Agentic AI
& Agentic AI framework with a \textbf{goal} to perform complex control gain calculations and controller evaluations. & Current implementation is restricted to linear systems and conventional control strategies (PID and loop-shaping). \\
\hline

\end{tabular}
\label{tab2}
\end{center}
\end{table*}

%\Figure[t!](topskip=0pt, botskip=0pt, midskip=0pt){fig1.png}
%{Magnetization as a function of applied field.
%It is good practice to explain the significance of the figure in the caption.\label{figX}}


\section{Domain Specific State-of-the-Art Use Case Illustrations of Agentic AI Systems in Electrical Engineering Applications}
\label{sec:guidelines}

At this point, we have developed clear taxonomical understanding of AI agents, generative AI, and agentic AI framework in section II and have seen the use cases of all three of these AI paradigms from a broader context of engineering and technology management in section III. In this section, we are going to discuss in-depth several domain-specific use case illustrations of agentic AI systems in the field of electrical engineering. 

Here it must be highlighted that up until 2024 the interaction between LLMs and external tools was fragmented and required bespoke plugins or proprietary APIs. This limitation kept LLM based AI agent interaction brittle, siloed, and hard to scale or audit. The mode of communication between LLMs and external tools revolutionized in 2025, with Anthropic’s introduction of the model context protocol (MCP) ~\cite{30_Anthropic,31_singh2025survey}, which was quickly adopted by the majority of the LLM powerhouses including OpenAI, Google, Meta, Microsoft, and Amazon. The wave of accessibility ~\cite{32_ray2025survey} offered through MCP’s capability-oriented way for models to discover tools and exchange structured inputs/outputs accelerated innovation across industries, including the electrical engineering sector.

In the field of electrical engineering, the impact was felt almost immediately, with developers creating custom MCP ~\cite{33_Poweragent}, thereby allowing an LLM-based agentic system to orchestrate heterogeneous software components, such as power-flow solvers, contingency analysis and protection studies, electromagnetic transient (EMT) simulation modules, asset health services, along with office productivity applications. As an evolving alternative workflow, natural language-based goals can now be passed into an agentic AI framework, which decomposes the task and passes it to its AI agents, which leverage MCPs to access powerful tools such as power system simulation or computer graphics software. Under this evolving framework, engineers can now specify a goal to an agentic AI system such as \textit{“run benchmark an array of power system simulation software, and perform a power flow analysis and a harmonic study with and without filter banks using the best performing simulation software, draft end-results with simulation plots and a compliance checklist”}, and allow the system to plan the work sequence, validates parameters against schemas, executes calls, tracks artifacts, and automatically recover from errors with structured retries. The added benefit is that with the intent now being declared in natural language rather than being hard-wired, instructions between specialist AI agents can be ported, provided valid MCPs exist. This not only reduces integration overhead but also makes agentic intelligence a practical, auditable solution for end-to-end engineering workflows. 

For agentic AI workflows, the common starting point is to ramp two or three pilot projects driving them to organizational maturity level. Once such a level of maturity is reached, an organization might be able to compare a broader set of other use cases based on their business impacts and implementation complexity and decide on selecting the ones with the highest business impacts provided the tools and techniques to bridge the implementation complexity is within reach. Table~\ref{tab3} outlines a collection of such use cases, shortlisted in consultation to in-house AI strategists, and decomposed in terms of business score and implementation complexities. The use cases with the highest scores in both categories are deemed as suitable candidates for further development into an agentic AI framework under pilot implementation.


\begin{table*}
\begin{center}
\caption{Scoring breakdown was created in consultation with AI strategist to quantify the nine electrical engineering agentic AI use cases in terms of business impact and implementation complexity}
\label{table}
\setlength{\tabcolsep}{3pt}
\begin{tabular}{|p{110pt}|p{110pt}|p{110pt}|p{50pt}|}
\hline
Agentic AI use cases& Business impact& Implementation complexity& Overall score \\
\hline
Distribution level asset: event detection and diagnostic
& Limited incremental business value; localized optimization potential in asset monitoring
\par \textbf{Score: 1/5}
& Technically straightforward; mature algorithms exist; minimal integration overhead
\par \textbf{Score: 1/5}
& \textbf{2/10} \\
\hline

Congestion forecasting and renewable curtailment
& Useful for operational visibility but limited direct customer monetization
\par \textbf{Score: 2/5}
& With robust SCADA in modern power system data availability is fairly easy, low real-time control integration complexity
\par \textbf{Score: 1/5}
& \textbf{3/10} \\
\hline

Renewable energy forecasting and planning
& Indirect customer value via improved grid planning and operational foresight
\par \textbf{Score: 2/5}
& Involves multi-timescale forecasting, meteorological inputs, and planning models
\par \textbf{Score: 3/5}
& \textbf{5/10} \\
\hline


Substation SCADA alarm and management
& Moderate operational benefit through reduced alarm fatigue and response time
\par \textbf{Score: 1.5/5}
& Requires structured data ingestion from SCADA, basic agent coordination
\par \textbf{Score: 4/5}
& \textbf{5.5/10} \\
\hline

PSPS for wildfire mitigation
& Very high business value due to safety, regulatory, and reputational considerations
\par \textbf{Score: 4/5}
& Operational triggers well-defined; relatively low integration and orchestration complexity
\par \textbf{Score: 2/5}
& \textbf{6/10} \\
\hline

RFQ to BoQ for engineering services and EPC
& High commercial value through automation of bid development and engineering cost reduction
\par \textbf{Score: 3.25/5}
& Moderate to high complexity due to natural language to structured BoQ translation workflows
\par \textbf{Score: 3.25/5}
& \textbf{6.5/10} \\
\hline

Complex substation studies
& High value due to direct engineering productivity gains and reduced study turnaround time
\par \textbf{Score: 4/5}
& Involves multiple software orchestration, agent coordination, and high-fidelity modeling
\par \textbf{Score: 4/5}
& \textbf{8/10} \\
\hline

Power system studies and benchmarking
& High system-level value - enables complex power system simulation-based studies to be executed
\par \textbf{Score: 4.5/5}
& Requires a complex orchestration of multiple modeling environments
\par \textbf{Score:3.75/5}
& \textbf{8.25/10} \\
\hline


Survival analysis of EV pricing models
& High value for strategic planning and business model forecasting. Adoption of the correct pricing model may mean survivability of an EV charging/swapping provider.
\par \textbf{Score: 5/5}
& Advanced statistical knowledge required
\par \textbf{Score:5/5}
& \textbf{10/10} \\
\hline

\end{tabular}
\label{tab3}
\end{center}
\end{table*}


Based on the scoring from Table~\ref{tab3}, the nine use cases are plotted in Figure~\ref{fig3} for ease of visualization, and the four highest scoring cases (deep blue) are developed further, with details of each of the agentic AI framework (along with limitations,lesson learned, and extensions) provided in sections III.A through III.D.



\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{Figure_2.2.png}
    \caption{Prioritization guide for developing agentic AI frameworks while maximizing business impacts for hard-to-implement tasks.}
    \label{fig3}
\end{figure*}

\subsection{Case study of MCP based agentic AI framework for streamlining of power system studies and benchmarking}

The first case study presents an agentic AI framework showcasing how a group of specialized AI agents having access to power system simulation tools via MCP be used for benchmarking of power system simulation software with the goal of assessing the best run times and computation accuracy. Traditionally, for power system studies such as power flow, contingency analysis, and transient simulation analysis, system engineers need to learn the intricacies of simulation tools such as \textit{PSS®E, PowerWorld, DIg-SILENT}. Often, one may have to leverage multiple software to accomplish a complex study objective, and mastering a full-stack workflow takes years and often poses a huge entry barrier for early-career professionals. With an agentic AI workflow, the engineer will not need to master the inner working of each of these programs and can focus on high level decision making and directing the agentic AI system to handle the program-interface level tasks. Based on its benchmarking assessment, the agentic AI framework may use the most relevant set of simulation software, based on simulation capability, run time, and accuracy. With an agentic flow such as the one proposed in Figure~\ref{fig4}(a) such an objective can be achieved, with the agentic AI framework benchmarking the different software that is available to it, and subsequently decomposing a complex simulation task and leveraging the constituent AI agents as needed to provide the final outcome. A contrasting traditional and standalone pandapower workflow is shown in Figure~\ref{fig4}(b) where a system user has to stepwise create a network model, compile code to run the desired power system studies, and manually document and assess the results. Depending on the objectives, one may have to orchestrate a full simulation study manually across multiple software to be able to compile final results. 

Figure~\ref{fig4}(c) shows an improvement over Figure~\ref{fig4}(b) with illustration of the prompts and the outputs of a standalone “pandapower AI agent”. Instead of working inside the coding environment of the pandapower software, an user can leverage this AI agent and upload the desired network file and prompt the AI agent to execute a power flow, an N-1 contingency analysis, or a short circuit study, and generate the output in a desired reporting format. 

As one may observe, an agentic AI framework poses much higher degree of autonomy and adaptability, compared to constituent AI agents. Given its goal-oriented nature, it can benchmark software performance and use these benchmarking results to intelligently invoke the most appropriate set of software (via orchestrator and delegator) to execute a complex power system study. In contrast, a standalone AI agent can perform a very limited set of tasks without any goal decomposition or multi-agent coordination capability. Critical evaluations of this case study are outlined as follows:
\begin{itemize}
    \item \textbf{Success-} The power system agentic AI framework was able to successfully benchmark several power system studies, such as power flow, contingency analysis, etc. across \textit{pandapower, PSS®E, PowerWorld}. Based on its benchmarking results and fulfilling its subsequent goal, it was able to intelligently decompose a multi-objective system study, selecting the most well-suited specialized agents, and ultimately generating a full study report.
    \item \textbf{Limitations-}At the time of writing this manuscript, none of the power system software providers offered standardized official MCPs, compliant with stable version of their software. Having standardized and stable versions of vendor-provided MCP would allow for wider collaboration on these agentic workflows.
    \item \textbf{Lessons learned-} Depending on the nature of the prompt that was used, it was observed that at certain times, the agentic AI framework tried to read or rewrite the entire network file before passing it to the power system software for processing. When this happened, the LLM token limits were quickly reached, and subsequent steps were aborted.
    \item \textbf{Extensions-} The framework can be extended for more complex benchmarking and power system studies. For example, the agentic AI framework can be further developed for DER interconnection screening, or other specialized studies such as distribution system loss/efficiency studies. Results from a constituent AI agent, such as the \textit{OpenDSS} specialist agent maybe subsequently fed to a \textit{PowerWorld} AI agent to perform an optimal power flow with qualifying DERs and generating the MW marginal costs.
\end{itemize}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{Figure_1adjusted.png}
    \caption{Agentic AI framework for power system benchmarking. \textbf{(a)} Detailed agentic AI framework with an ensemble of specialized AI agent and well-defined goal(s). \textbf{(b)} Native pandapower code structure shown for creating an electrical network and executing a power flow, a contingency analysis, and short circuit studies. \textbf{(c)} An AI agent-based workflow with an user prompting into a standalone “pandapower AI agent” to invoke pandapower and have it perform power flow, contingency analysis, and short circuit analysis.}
    \label{fig4}
\end{figure*}

\subsection{Case study of MCP based agentic AI framework for enhancement of substation illumination studies}

The second case study presents an agentic AI framework, showcasing how a group of specialized AI agents can collaboratively automate and streamline an entire electrical substation illumination calculation and reporting workflow. An illumination study is a vital component of overall substation design, as there are industry guidelines, such as the National Electric Safety Code (NESC) section 111-1 ~\cite{34_NESC}, which necessitate certain levels of illumination levels that must be maintained within the substation yard and around the major electrical equipment to ensure safe operation and maintenance at night. Traditionally yard luminaires are placed on lightning masts, bus support or take off structures, within an illumination computation software such as \textit{AGI32} or \textit{Acuity Brand’s Visual Lightning} by the substation design engineer. The quantity of the luminaires to be placed is usually determined by the overall footprint of the substation and the lo-cation of the major electrical equipment within. Usually, zoning restrictions apply, and care is taken to reduce any excessive bleeding of light outside the substation perimeter fence.  

Our proposed agentic AI system facilitates this entire process, with the framework outlined in Figure~\ref{fig5}(a). The process usually starts with defining a set of goals that the agentic AI framework should aim to achieve. With the general outline of a substation fed into the agentic AI framework, it can intelligently evaluate the major equipment, such as circuit breakers, transformers, switches, etc., and can search its internal database to see if matching 3D models for these major pieces of equipment exist. If a match is not found, the orchestrator can invoke a “specialist 3D modelling agent”, which leverages Blender’s modelling capability via MCP and custom generate the missing 3D models for such equipment from catalog 2D prints, see Figure~\ref{fig5}(b). Once all the 3D models are available (either from internal database or generated), the orchestrator within the framework triggers the illumination software via MCP (Figure~\ref{fig5}(c)) and iteratively works through the different approve exterior light fixtures, their placement, and orientation, to come up with an optimized illumination plan. An efficient way to achieve this would be to use a grid search pattern between the different varying parameters. The set of goals for this agentic AI framework are to ensure that:
\begin{itemize}
    \item Calculation points outside the substation zone have illumination of 0.2-foot
    candle or less, thereby preventing unnecessary light bleeding out,
    \item Calculation points near major equipment are at least at 5-foot candle, ensuring
    safe nighttime operation near these high voltage equipment, and
    \item No calculation zone is over illuminated (defined at 30-foot candles or more),
thereby avoiding any hot-spot.
\end{itemize}
Critical evaluations of this case study are outlined as follows:
\begin{itemize}
    \item \textbf{Success-} The agentic AI methodology was successfully able to output an NESC
compliant illumination report based on set goals for a six-position ring bus station
and a three-bay breaker and a half station.
    \item \textbf{Limitations-} Given that even low-resolution mesh models have a significantly
higher number of polygon count compared to primitive shapes, software memory
constraints were observed. The agentic AI setup was unable to generate a report
for a four bay-bay breaker and a half station on standard i9, 64 GB RAM hardware.
    \item \textbf{Lessons learned-} An agentic AI substation illumination study workflow is
especially valuable for compact, brownfield substations that may benefit from a
detailed illumination analysis. By generating 3D mesh models directly from catalog
drawings, the agentic system reduces engineering effort and cost.
    \item \textbf{Extensions-} Similar to the agentic AI substation illumination study workflow,
pipelines could be developed to leverage a collection of AI agents to perform a
substation grounding study, with a predefined agentic goal. In such an agentic
workflow, a subagent may choose to intake the soil resistivity data and generate a
CDEGS soil model, a second subagent may validate the generated soil model
against the geotechnical report, while a third subagent develops the touch and step
potential plots, with a parent agent compiling an end-to-end technical report.
\end{itemize}   


\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{Figure_3.png}
    \caption{Agentic AI framework for developing NESC code compliant illumination study reports for sub-station applications. \textbf{(a)} Autonomous agentic AI pipeline with specialist AI agents generating custom substation equipment 3D models and optimizing the placement of the yard luminaires. \textbf{(b)} 3D specialist agent generating custom substation equipment 3D model. \textbf{(c)} Snippet of the “simulation agent” going through multiple iterations and selecting the best set of parameters thereby yielding an optimized station illumination plan.}
    \label{fig5}
\end{figure*}

\subsection{Case study of an agentic AI framework to generate engineering bill of quantity
(BoQ) based on request for pricing (RFQ) documents}

As its business model, engineering consulting firms often receive requests for
pricing (RFQ) from electrical utilities and developers with the expectation to provide
competitive proposals including bill of quantities (BoQ), often under an aggressive
bidding timeline. An incoming RFQ may contain several sets of documents identifying
the scope of the engineering work being solicited, including high-level engineering
schedule, engineering drawings, along with applicable bidding rules and exceptions. It
often takes a full engineering team to analyze these documents, comparing the RFQ
documents against engineering design standards and historical project examples, with
the ultimate goal of preparing a bottom-up engineering estimate for the bill of quantities
(BoQ). A BoQ is a detailed document that itemizes, quantifies, and describes all the
materials, parts, and labor required to complete a construction or engineering project,
along with their estimated costs.

An agentic framework may streamline the entire process by using an RFQ to
generate an engineering BoQ. Such a framework is shown in Figure 6(a) and comprises of: 
\begin{itemize}
    \item A contextual retrieval augmented generation (RAG) agent to retrieve pertinent
information from the engineering standard design documents based on a
contextual retrieval process,
    \item A reference project assessment agent providing bill of material quantities from
similar reference projects that were executed in the past, and
    \item A master compiling agent, which compiles an BoQ report, based on specific
formatting requirements.
\end{itemize}

Under an agentic AI framework, the orchestrator autonomously dissects the RFQ
documents and requests the delegator to invoke the contextual RAG agent to ensure the
estimation of quantities are compliant with engineering standard design. For example,
the delegator might ask the contextual RAG agent to refer the engineering design
standards on \textit{“what is the grounding grid burial depth of the grounding conductors for a
substation installation?”} and based on the retrieved depth information produce a labor
related pricing to install the grounding grid at the recommended depth. The orchestrator
also has the autonomy to consult the “reference project assessment agent” via the
delegator, which returns comparable estimates from previous projects. Leveraging these
two subagents, a “master compiling agent” sequentially compiles the BoQ. With each
BoQ compilation, a human evaluation can be done to ensure accuracy and an accuracy
score, serving as a KPI, can be provided back to the agentic AI as a feedback for
sequential improvements.

It is worth noting that, in cases like the one presented here, a context-aware RAG
system offers distinct advantages over a traditional RAG setup ~\cite{35_ghosh2025low}. By enriching
each chunk with its surrounding textual elements, such as section titles, headers, or
preceding paragraphs, during the embedding process, the retriever can better preserve
both the semantic flow and the original document structure. A full contextual RAG
framework, along with relevant chunking prompts, and folder contexts are shown in
Figure~\ref{fig6}(b) through Figure~\ref{fig6}(d), with Figure~\ref{fig6}(b) showing the details of the pipeline,
Figure~\ref{fig6}(c) showing the engineering standard design files in Google Drive containing
documents such as substation civil and structural design guidelines, relaying and
protection system standard document, etc., and Figure~\ref{fig6}(d) showing the details of the
exact prompt within the “Basic LLM Chain” block that generates the contexts for each
chunk. Some sample queries that were sent by the delegator to the contextual RAG
agent are shown in Figure~\ref{fig6}(e).
Critical evaluations of this case study are outlined as follows:
\begin{itemize}
    \item \textbf{Success-} Under a pilot implementation, such an agentic AI framework was
successfully able to digest lightweight RFQ documents, autonomously consult the
subagents and compile a BoQ in an excel format.
    \item \textbf{Limitations-} Though the agentic AI framework significantly reduced timing and
rapidly provided a BoQ given a set of RFP documents, accuracy remained a
concern, as there were frequent over or under estimation. Estimation range of the
agentic BoQ as compared to a fully human compiled engineering BoQ fell within ±
70\%, indicating a higher degree refinement to the agentic AI framework being
needed.
    \item \textbf{Success-} Under a pilot implementation, such an agentic AI framework was
successfully able to digest lightweight RFQ documents, autonomously consult the
subagents and compile a BoQ in an excel format.
\end{itemize}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{Figure_2adjusted.png}
    \caption{Agentic AI framework for developing engineering bill of quantities (BoQ) based on request for pricing (RFP) documents. \textbf{(a)} An end-to-end agentic AI pipeline with agents leveraging contextual RAG and sample bill of material quantities from similar reference projects to generate project-specific bill of quantities (BoQs). \textbf{(b)} A detailed contextual RAG framework for context aware retrieval from engineering standard documents. \textbf{(c)} Folder structure of the engineering design standards within Google Drive. \textbf{(d)} Prompt residing within the “basic LLM chain” block for contextual segmentation. \textbf{(e)} Testing of the agentic AI framework with the delegator generating necessary prompts to retrieve information from the contextual RAG system based on engineering standards.}
    \label{fig6}
\end{figure*}

\subsection{Case study of an agentic AI system for survival analysis of battery swapping station
pricing strategies}

This next case study illustrates the application of another agentic AI framework to
identify the most suitable pricing strategy for electric vehicle (EV) battery swapping
stations using survival analysis, from a collection of competing pricing strategies. This
form of survival analysis is often helpful when a firm rolls out multiple EV charging
pricing strategies; examples being market competition versus usage driven pricing ~\cite{37_ghosh2025architecture} ,
online/offline auction or non-auction based pricing ~\cite{38_limmer2019dynamic,39_ma2011decentralized,40_gerding2011online}, profile based versus
session based pricing ~\cite{38_limmer2019dynamic,41_guo2014economic,42_soltani2014real},  as part of its pilot project and would like to identify the
one that would result in the best future outcome/growth. Traditionally, evaluating pricing
strategies involves manual retrieval, cleanup, and analysis of the pricing/performance
data which can be both time-intensive and susceptible to bias. Our agentic AI system
streamlines this process by integrating AI agents capable of retrieving the pricing data
and invoking R Studio via the MCP ~\cite{43_Claude}, for cleanup and automated survival analysis,
and generation of actionable business intelligence as an end result.

Survival analysis is particularly well-suited for this task since it models both the time
to event and whether the event occurred. In this context, the event of interest is defined
as \textit{"the first instance when a pricing model yields profits of >  USD 150,000"}. The goal of the
agentic AI framework is to recommend the EV pricing model that is most likely to
generate the given levels of profit, leveraging survival analysis tools and techniques.
During the data collection period, observations where this threshold was not reached
within the study period are treated as censored, meaning the event may occur in the
future but were not observed during the 12 months of follow-up for each customer.
To simplify the analysis, the dataset used in this study contained no additional
covariates. The primary goal was to compare the performance of two pricing models in
terms of their ability to reach the profitability threshold within a given timeframe. The
agentic AI framework is shown in Figure~\ref{fig7}(a) with the final output being a
comprehensive business intelligence report compiled by the constituent AI agent,
integrating both the survival analysis agent and a pricing data retrieval. The agentic AI
generated report offers actionable KPI improvement strategies, such as adjusting pricing
tiers, introducing dynamic pricing, or bundling services to enhance customer retention
and profitability.

The workflow begins with the orchestrator being fed the desired goal, and the
delegator invoking the data retrieval agent (shown in Figure~\ref{fig7} as pricing data compiling
agent) to load the necessary data file. A sample data from such a file is shown in Figure~\ref{fig7}(b). The orchestrator/delegator subsequently invokes a second specialized survival
analysis subagent, which executes a complete survival analysis workflow in R Studio via
MCP. The final output, by the agentic AI includes (also see Figure~\ref{fig7}(c)):
\begin{itemize}
    \item Kaplan-Meier survival curve estimation
    \item Log-rank test for comparing survival distributions
    \item Cox proportional hazards modeling to estimate hazard ratios with 95\%
confidence intervals
\end{itemize}

This report includes visualizations of survival curves, statistical comparisons, and
recommendations for the pricing model that demonstrates superior profitability
performance. If the proportional hazards assumption is violated, the agentic AI
framework by virtue of its autonomy flags this and switches to a stratified Cox model ~\cite{44_klein2006multivariate}, which accommodates non-proportional hazards while still providing interpretable
hazard ratios with confidence intervals.

The agentic AI system operates within a similar hierarchical structure enabled by
AutoGen, allowing seamless coordination between specialized agents. Key evaluations
of this case study include:
\begin{itemize}
    \item \textbf{Success-} The agentic AI system successfully identified the most effective
pricing strategy across three metropolitan regions, resulting in an 18% improvement in
customer retention compared to baseline.
    \item \textbf{Limitations-} The accuracy of survival analysis depends heavily on the
quality and granularity of input data. In cases where survival curves overlap significantly,
more complex modeling techniques may be required, increasing computational
demands.
    \item \textbf{Lessons learned-} Agentic AI workflows are particularly valuable in dynamic
pricing environments where rapid iteration and data-driven decision-making are
essential. Automating survival analysis reduces human error and accelerates strategic
optimization.
    \item \textbf{Extensions-} This survival analysis based agentic AI framework can be
extended to other EV infrastructure domains, such as estimating the time period for a
commercial EV battery pack to reach end of useful life. Another excellent use case of
survival analysis in the EV swapping industry may consist of an agentic AI system
analyzing first life EV battery degradation, cycling history, and thermal events to
autonomously classify such first life EV batteries at the end of their useful life for less
demanding grid storage applications.

\end{itemize}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{Figure_4adjusted.png}
    \caption{Agentic AI workflow for improving EV battery pricing KPI. \textbf{(a)} Agentic AI framework showing the integration of the survival analysis agent with a pricing data compiling agent capable of generating business intelligence and KPI improvement recommendations. \textbf{(b)} Structure of the input dataset with two pricing models (A and B). \textbf{(c)} The agentic AI framework obtaining the raw data, performing a full survival analysis and generating a recommendation report.}
    \label{fig7}
\end{figure*}

\section{Failure Mode Investigations and Recommendations for Safe and
Accountable Agentic AI Systems}

\subsection{Adversarial spread of false information among networked LLM agents and mitigation
strategies}
\subsubsection{Background and illustration of false information injection and propagation}
{Compared to traditional AI agent-based systems, an agentic AI system has a much
broader attack surface susceptible to malicious false (manipulated) data injections. As
agentic AI systems witness broader implementation, the security implications of these
LLM-based systems are yet to be fully understood. One significant attack vector is the
injection and spread of manipulated knowledge. The vulnerability exists because all the
constituent agents are not exclusively managed by a single hosting platform. A malicious
agent hosted by a third-party platform and part of the agentic AI framework can embed
malicious information which can then spread within the LLM models of other AI agents,
thereby compromising the whole agentic system. The concept is further illustrated in
Figure~\ref{fig8}.}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{Figure_5adjusted.png}
    \caption{Adversarial false data injection attack poisoning the collective memory of the AI agents within the Agentic AI framework.}
    \label{fig8}
\end{figure*}

\subsubsection{Proposed mitigation strategy with zero trust framework to counter false data
injection and propagation}
{To address this critical vulnerability, we propose the adoption and adaptation of a
Zero Trust Framework (ZTF). Originating in network security, ZTF is a strategic
paradigm built on the principle of \textit{"never trust, always verify"}. It fundamentally shifts
security from a static, perimeter-based model to a dynamic, identity-centric approach
where trust is never granted implicitly. Instead, it must be continuously and explicitly
verified for every transaction. In the context of an agentic AI framework, this means no
agent is trusted by default, regardless of its origin (internal or third-party) or its previous
interactions. Every request for data access or communication must be treated as a
potential threat. We adapt the core tenants of ZTF to this domain as follows:
\begin{itemize}
    \item \textbf{Strong agent identity and authentication:} Every agent within the
framework must possess a strong, verifiable cryptographic identity (e.g.,
X.509 certificates or SPIFFE Verifiable Identity Documents) ~\cite{45_cochak2024lightweight,46_sedlmeir2021digital}. All
agent-to-agent communication must be secured using mutual TLS (mTLS),
ensuring that both parties are authenticated before any information is
exchanged. This prevents agent spoofing.
\item \textbf{Micro-segmentation and least privilege access:} The framework must be
aggressively micro-segmented ~\cite{47_klein2019micro}. Agents should be isolated by default
and only allowed to communicate with other agents or access data stores
that are explicitly required for their defined tasks. This \textit{"least privilege"};
model ensures that even if an agent is compromised, its \textit{"blast radius"}; is
contained. It cannot propagate false information to segments of the system
unrelated to its function.
\item \textbf{Continuous verification of information integrity:} Continuous verification
is the most critical adaptation for LLM-based systems. Trust cannot end at
the agent level; it must extend to the data itself. We propose a multi-layered
verification strategy:
    \begin{itemize}
        \item \textit{Data provenance:} All significant data points or facts generated or
            propagated by an agent must be accompanied by secure,
            immutable metadata detailing their origin and transformation
            history (i.e., data provenance) ~\cite{48_imran2017provenance}. This allows for auditing and
            tracing false information back to its source.
        \item \textit{Consensus-based verification:} For critical decisions or updates to a
            shared knowledge base, the system should require consensus
            from a quorum of independent, authenticated agents. A single
            agent's input, especially if it contradicts established knowledge,
            should be flagged for review and not be immediately accepted.
        \item \textit{Plausibility monitoring:} An independent "evaluator" or "auditor"
            agent service can be implemented to continuously sample and
            analyze agent outputs. This auditor, using a set of trusted
            heuristics or a sandboxed foundational model, would check for
            factual consistency, logical contradictions, or alignment with
            known-good data.
    \end{itemize}

\item \textbf{Dynamic monitoring and behavioral analysis:} The ZTF model mandates
continuous monitoring. The system must actively log and analyze agent
behavior, communication patterns, and resource requests. Anomaly
detection models can be trained to identify deviations from an established
baseline (e.g., an agent suddenly attempting to access new data, or a
sudden shift in the semantic content of its outputs). Such deviations would
trigger an immediate re-verification of the agent's identity and quarantine it
from the network pending review. 
\end{itemize}
By applying this Zero Trust Framework, with the essence summarized in Figure~\ref{fig9} for
ease of visualization, the agentic AI system moves from a vulnerable state of implicit
trust to a resilient posture of explicit, continuous verification at both the agent and data
layers.
}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{Figure_9adjusted.png}
    \caption{Zero trust framework for mitigating adversarial information propagation in agentic AI systems.}
    \label{fig9}
\end{figure*}

\subsection{Cascading misinformation from LLM rewrites in Agentic AI systems and mitigation
strategy}
    \subsubsection{Background and illustration of misinformation propagation from LLM rewrites}
In an agentic AI system, information is propagated between a sequential (or
hierarchical) network of AI agents. As AI systems generate and process ever-more
information, AI agents risk propagating false information thereby contaminating the
shared pool of knowledge and distorting the intermediate instructions ~\cite{49_huang2023generative} ultimately
resulting in misaligned outcomes. To demonstrate the cascading misinformation problem
from LLM rewrites, we created an agentic AI system, see Figure~\ref{fig10}(a), with multiple AI
subagents. The first subagent functioned as a contextual RAG specialist, while the other
subagents in series took the output from the RAG agent, processed the incoming
information for its own specialty application and passed the instruction along to the next
subagent.

We performed an experiment on a collection of thirty (30) curated, domain-specific
search queries to the National Electrical Code (NEC) ~\cite{50_NFPA}, a fundamental electrical design codebook that is relied on by practicing electrical engineers. The contextual RAG specialist subagent had access to a contextually parsed version of the NEC. Input and output of each of the six subagents were recorded. For scoring, we used the correctness measure of DeepEval (open-source LLM evaluation framework) ~\cite{51_DeepEval} with GEval (DeepEval metrics) criteria. The measure examines the degree of semantic consistency, factual accuracy, and contextual coverage between the generated response and the ground truth. The GEval metric provides a detailed evaluation based on the following
criteria:
\begin{itemize}
        \item \textit{Grounding:} Did the model reference or integrate pertinent language from the
retrieved National Electric Code (NEC) or other equivalent section?
        \item \textit{Exactness:} In terms of exactness, did the LLM output able to accurately deduce
essential quantitative thresholds and regulatory stipulations?
        \item \textit{Verifiability:} Can the assertions made by the LLM output be traced back to the
source sections of the document?
\end{itemize}
It was observed that each subsequent agent, leveraging an internal Claude Sonnet
4.5 LLM model, rewrote the information slightly differently, and the essential information
content started to lose context after the second or third rewrite. The context generally
turned out to be completely off topic after the fifth rewrite. One such prompt, with the
reference ground truth, the response by the RAG subagent, and subsequent rewrites by
subagents are shown in Figure~\ref{fig10}(b), with the evaluation and scoring provided by
DeepEval with GEval. Repeating the scoring process with thirty (30) curated prompts
and scoring the response of the RAG subagent and the subsequent subagents, the
accuracy versus rewrite scoring plot at 95\% confidence interval (CI) was obtained, see
Figure~\ref{fig10}(c).


\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{Figure_6adjusted.png}
    \caption{Degradation of information accuracy as it propagates and gets rewritten by AI agents. \textbf{(a)} The agentic AI framework with an RAG agent and other specialized agents. \textbf{(b)}  Illustration shows how information while getting rewritten may show a sharp degradation of accuracy after the second and third rewrites. \textbf{(c)}  Accuracy score with 95\% confidence interval from thirty user (30) prompts with its responses and rewrites with Claude Sonnet 4.5 as the language model.}
    \label{fig10}
\end{figure*}



\subsubsection{Proposed mitigation strategy to counter misinformation propagation}
The mitigation strategy as proposed here in this section may consist of an agentic
AI architecture, where information passed between the AI agents contains data packets,
with each data packet comprising of two separate inner clusters:
\begin{enumerate}[label=(\alph*)]
\item one of these clusters is set such that the information received by the AI agent
may be processed ‘as-is’ by the agent’s in-built tools but reinterpreted or rewrites by
its chat model during receipt or transmission is strictly forbidden,
\item the other cluster is designed such that the information received can be
reinterpreted by the AI agent’s chat model and either the original or rewritten
information can be passed to the agent’s tools.
\end{enumerate}
A high-level human-in-the loop (or a parent-AI-agent-in-the-loop) may determine the type
of information that goes into each of these clusters. Alongside this information clustering
(into two separate baskets), each AI agent needs an interlinked ‘guard signal’ to ensure
continuity in the chain. The concept is illustrated in Figure~\ref{fig11}, and such architecture is
capable of preventing accuracy degradation with LLM rewrites between AI agents in an
agentic workflow.

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{Figure_6.1.png}
    \caption{Mitigation strategy to prevent degradation of information accuracy as it passes through multiple AI agents in an Agentic AI framework.}
    \label{fig11}
\end{figure*}

\subsection{Other practical considerations in building trustworthiness in agentic AI deployment}
\subsubsection{Control mechanisms with frameworks containing human-in-the loop and human-
on-the-loop}
\begin{itemize}
    \item \textbf{Concept:} The autonomous nature of agentic AI systems allows for faster
task executions which comes as a distinct advantage in a pipelined
workflow involving multiple steps and decision-making processes.
However, such a system can greatly benefit from a \textbf{human-in-the-loop
(HITL)} allowing the human to approve of the intermediate steps and
intervene if necessary. The concept of human-in-the-loop is a matured
technique and has witnessed implementation in standalone machine
learning and AI agent workflows for data preprocessing/annotation and
model training and inference ~\cite{52_wu2022survey,53_shneiderman2020human}, and thus can be borrowed for an
agentic AI framework. A comparable concept of \textbf{human-on-the-loop
(HOTL)} in an agentic AI framework allows for slightly lesser degree of
human autonomy where a human serves as a supervisor of intermediate steps and deciding actions, instead of an approver. The presence of such
human intelligence-based checks and bounds is essential in engineering
agentic AI system development where the systems interface with the
general public directly or indirectly, and are responsible for their health,
safety, and wellbeing.
    \item \textbf{Recommendation:} For initial deployment, an agentic AI system should be
designed with greater checks and bounds under an HITL framework. Only
after subsequent pilot or field testing and satisfactory performance
demonstrations should the framework be changed to a HOTL system.

    \item \textbf{Case study:} To illustrate the HITL/ HOTL concepts in context to agentic
AI, we revisit section III.C, \textit{‘Case study of an agentic AI framework to
generate engineering bill of quantity (BoQ) based on request for pricing
(RFQ) documents’}, to observe some of the implementation level details.
The incoming test RFQ requests for an all-inclusive quotation for
engineering, procurement, and construction (EPC) services for a four-
position ring bus green field electrical substation at 345 kV. The test RFQ
contains explicit instructions to provide two separate pricings, one with
Siemens 362 kV rated circuit breakers and the other with MEPPI 362 kV
rated circuit breakers. The agentic AI had the autonomy to consult internal
procurement databases for major equipment, steel, foundation pricing,
specialized reference project database for labor hours and rates. The
agentic AI also had the autonomy to query engineering standards-related
questions with its specialized contextual RAG agent. Upon completing the
intermediate steps, the agentic AI framework provides the following results,
as documented in Table~\ref{tab4}.



\begin{table*}
\begin{center}

\caption{Price breakdown for EPC option A versus B}
\label{table}
\setlength{\tabcolsep}{3pt}
\begin{tabular}{|p{100pt}|p{120pt}|}
\hline
EPC option& Pricing breakdown \\
\hline

EPC Price Option A \par w/ Siemens 362 kV  & Engineering services - \$ 320,000
\par Procurement – \$ 4,800,000
\par Construction - \$ 3,250,000
\par \textbf{Total EPC pricing - \$ 8,370,000} \\

\hline

EPC Price Option B \par w/ MEPPI 362 kV  & Engineering services - \$ 328,000
\par Procurement – \$ 5,040,000
\par Construction - \$ 3,250,000
\par \textbf{Total EPC pricing - \$ 8,618,000} \\
\hline

\end{tabular}
\label{tab4}

\end{center}
\end{table*}



    Given that this is a pilot implementation with a revenue range of a few million dollars, a HITL was added, with the human tasked to check the logs to ensure any discrepancies or unintended behaviors are addressed before the pilot implementation is concluded. Upon checking the logs, see Figure~\ref{fig12}, it was observed that the agentic AI rightly queried the contextual RAG agent for necessary engineering design standards related questions. It also correctly estimated the labor rates based on reference projects of similar size. Further, the agentic system was able to correctly identify most of the substation major equipment, steel, and foundations, and was accurate in estimating the control house pricing. However, for option B (with MEPPI 362 kV rated breakers) during the human approval stage, it was noted that the framework appeared to have arbitrarily generated the pricing based on Option A and added a 2.5\% escalation on engineering and 5\% escalation on procurement. This unexpected behavior raises two questions:

\begin{enumerate}[label=(\alph*)]
\item \textit{Question 1: Was it possible to trace this error/omission without a HITL
intervention.}

\textit{Answer 1: The error/omission could have been traced once an audit of the
agentic AI’s logging systems was conducted. However, until such an
audit is conducted, the error could have remained in the system, and the
unexpected behavior could have had a real time impact. Having an HITL
allows for a more on-spot check on the behavior of the agentic AI
framework.}

\item \textit{Question 2: Why did the agentic AI framework not use its known capability to
browse the internal database to retrieve pricing information for the MEPPI
breakers?}

\textit{Answer 2: Further investigation reveals that the agent was unable to use
the MEPPI breakers information because the database labelled the
category as Mitsubishi breakers instead of MEPPI.}
\end{enumerate}

\end{itemize}


\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{Figure_2.1adjusted.png}
    \caption{A HITL added into the agentic AI framework to generate engineering bill of quantity (BoQ) based on request for pricing (RFQ) documents. }
    \label{fig12}
\end{figure*}



\subsubsection{AI governance standards and framework adaptations at government, corporate,
and institutional levels}
Corporate implementation of AI principles is often siloed behind a cloak of privacy
and confidentiality terms, preventing collaborative improvements on responsible use of
AI and its future evolution. To this end, governmental organizations are often a better
starting point for understanding AI governance framework. Once such example is the
‘Model Artificial Intelligence Governance Framework’ ~\cite{54_PDPC} (another governance
frameworks being ~\cite{55_demetzou2019data}), with its report delivered jointly by several Singaporean
governmental organizations, and providing recommendations that organizations could
readily adopt to deploy AI responsibly. An essential feature of the Model Framework is
its agnostic guidelines across four broad areas towards non-bias, explainability, and
privacy:
\begin{itemize}
    \item Algorithm agnostic – Not focusing on a particular AI methodology,
    \item Technology agnostic – Doesn’t focus on specific implementation, hardware or
software being used,
    \item Sector agnostic – In the sense that the framework is not domain specific,
    \item Scale and business model agnostic – The framework may be deployed to
organizations of any size and business model, whether B2B, B2C, or others.
\end{itemize}

Second to governmental driven frameworks, there exists some limited visibilities into
corporate AI principles and standards into ‘responsible AI’, mostly attributed to the
seminal work ~\cite{56_de2021companies}, as summarized here: 
\begin{enumerate}[label=(\alph*)]
\item Microsoft – Governance of internal responsible AI is driven by the company’s ‘AI and Ethics in Engineering Research Committee’ and by the ‘Office of Responsible AI’. Open-source tools such as the FairLearn ~\cite{57_Microsoft}, InterpretML ~\cite{58_Github}, and WhiteNoise packages are available for non-bias, explainable, and privacy preserving AI implementations.
Responsible AI’. Open-source tools such as the FairLearn ~\cite{57_Microsoft}, InterpretML ~\cite{58_Github}, and WhiteNoise packages are available for non-bias, explainable, and privacy preserving AI implementations.
\item Google – The ‘Responsible Innovation’ teams is tasked with the review of new
first-of-a-kind projects to ensure conformity to AI principles. Additionally, open-
source tools like Facets ~\cite{59_Google_Research}, What-If ~\cite{60_Google_Research}, CleverHans ~\cite{61_Cleverhans}, and Tensor Flow
Privacy are available for non-bias, explainable, and privacy preserving AI
implementations.
\item IBM – The ‘AI Ethics Borard’ chaired by IBM’s AI Ethics Global Leader and Chief
Privacy Officer drives the governance of responsible AI within the firm.
Additionally IBM has a collection of open-source toolkits such as AI Fairness 360
~\cite{62_TrustedAI}, AI Explainability 360 ~\cite{63_TrustedAI}, and Adversarial Robustness 360 ~\cite{64_TrustedAI} for non-bias, explainable, and privacy-preserving AI implementations. The company has also externally collaborated on funder collaborative research on responsible AI with at ‘Institute for Human-Centered AI’ at Stanford
University.
\end{enumerate}

In addition to governmental and corporate organizations, institutions like IEEE are
in the forefront of responsible AI research and standards development. Some
noteworthy mentions are:
\begin{enumerate}[label=(\alph*)]
    \item IEEE conference publications
        \begin{itemize}
            \item ~\cite{65_xia2024towards} – Manuscript covering a collection of metrics for AI accountability,
            \item ~\cite{66_lecca2025responsible} – Conference manuscript providing a practitioner centered perspective of transparency and accountability principles to fully operationalize ‘Responsible AI’ principles in software engineering,
            \item ~\cite{67_baeza2024responsible} – An important roadmap paper on ‘Responsible AI’ strategy. Includes
                    paradigms such as assessing models, processes, and products from an ethical
                    impact standpoint along with targeted staff training.
        \end{itemize}
    \item IEEE standards
    
    At the time of writing to the best of our knowledge there were no published
IEEE standards directly related to ‘Responsible AI’. The timeline to develop an
approved IEEE standard once a PAR is approved usually takes two to three
years. To that end, to following standards are in development with their
respective PAR’s approved in 2023-2024:
        \begin{itemize}
            \item ~\cite{68_IEEE_2840-2024} – This IEEE standard \textbf{P2840}, currently in development, pertains to
            ‘Responsible AI’ licensing,
            \item ~\cite{69_IEEE_P3396} – This IEEE standard \textbf{P3396}, currently in development, aims to provide recommended practice for understanding, defining, and evaluating AI risks, AI safety, AI credibility, and AI responsibility. This standard aims to touch on these pivotal issues surrounding the use of AI while balancing to preserve the benefits of AI in innovation,
            \item ~\cite{70_IEEE_P7999} – This IEEE standard \textbf{P7999}, currently in development, aims to integrate
            organizational ethics oversight in AI processes and procedures.
        \end{itemize}
\end{enumerate}

\subsubsection{Audit trails via self-documenting agentic systems}
While implementing human-in-the-loop supervision and relevant privacy and
governance standards are pivotal for agentic AI frameworks of tomorrow, having a
proper path to audit an agentic AI framework could differentiate between an agentic
framework that is compliant to a given standard versus a framework where all the steps
are traceable enabling developers to understand and improve the decision-making
process. Such self-documenting framework would allow developers to understand each
step of the autonomous decision-making process, thereby allowing such frameworks to
fully reproduce the outcomes. Though such agentic frameworks with self-documenting
algorithms are in its early stages of pilot implementation ~\cite{71_phiri2025creating,72_kacianka2021designing} , at a minimum they
would need self-documenting log files that store:

\begin{itemize}
            \item The algorithm setup,
            \item The version of the LLM being used by each AI agent,
            \item The MCPs being involved along with their version number,
            \item The system configuration and any relevant the random seed,
            \item The intermediate information files transmitted between the AI agents,
            \item Final solutions, and
            \item The progress of any optimization sub-algorithm or KPIs over time.

\end{itemize}
Understanding the internal structure of self-documenting log files is equally critical ~\cite{73_weise2023replicable},
as it ensures that any agent - whether self-managed or third-party, attempting to
manipulate the audit process, faces a significantly higher risk of adverse consequences.
Hence, some of the important characteristics self-documenting agentic AI log files
should possess are outlined in Table~\ref{tab5}.



\begin{table*}
\begin{center}
\caption{Preferred in-built characteristics self-documenting agentic AI log files should possess}
\label{table}
\setlength{\tabcolsep}{3pt}
\begin{tabular}{|p{120pt}|p{120pt}|p{120pt}|p{120pt}|}
\hline
Characteristics and useful references& Functional description & Intended security outcome & Implementation considerations\\
\hline
Immutable logging \par ~\cite{74_hu2021merkle,75_white2019black,76_cucurull2016distributed} & Log entries, once written, cannot be altered or deleted. All modifications must be versioned and traceable.& Prevents tampering and ensures forensic integrity of agent actions. & Use cryptographic hashing (e.g., Merkle trees), blockchain-style append-only ledgers, or WORM (Write-Once-Read-Many) systems. \\
\hline


Incremental penalty for repeat AI agent offenders \par ~\cite{77_mui2002notions} & Escalating penalties applied to AI agents based on repeat violations — e.g., restricted API calls, degraded privileges, or increased monitoring.& Discourages repeated audit gaming by rogue agents. & Define structured penalty tiers, maintain persistent offender history. \\
\hline


Redundant logging & Agents document events even if it is being written by more than one agent.& Survivability of critical audit data, even if one agent tries to suppress information. & Implementation should have time and geographical stamps to facilitate cross-validation.  \\

\hline
\end{tabular}
\label{tab5}
\end{center}
\end{table*}


\section{Conclusions and Future Work}

This paper has chartered the emergence of agentic AI as yet another transformative
paradigm, representing a significant evolutionary leap from traditional AI agents and
reactive generative AI. We demonstrated that agentic AI, characterized by their goal-
oriented autonomous behavior, task decomposition and planning capabilities, and ability
to orchestrate the constituent AI agents to interact with external tools, are moving AI to
the role of an active problem-solver. Our primary contribution has been to bridge the gap
between the high-level theory of agentic AI and its practical, high-stakes application
within the field of engineering. To achieve this, we first establish a clear and necessary
taxonomy, distinguishing the unique capabilities of agentic AI from its predecessors.
Four state-of-the art use cases in the field of electrical engineering are presented,
ranging from agentic AI based power system simulation software benchmarking and
simulation studies to automated substation illumination design, automated bill-of-quantity
generation, and advanced survival analysis for EV framework with the goal to identify the
most suitable profit maximizing pricing strategy.

However, this transformative potential is accompanied by significant risks. Our
investigation into failure modes identified critical vulnerabilities, including the adversarial
spread of false information and the cascading degradation of information accuracy
through successive LLM rewrites. In response, we proposed tangible mitigation
strategies, including the adaptation of a Zero Trust Framework (ZTF) to enforce
continuous verification of agent identity and data, and a novel information clustering
architecture to protect data integrity. Our technical solutions are complemented by
practical recommendations for deploying trustworthy systems, emphasizing the vital role
of Human-in-the-Loop (HITL), adherence to emerging AI standards, self-documented
immutable audit trails for better accountability of the constituent AI agents that forms the
agentic AI framework.

Looking ahead, while the potential of agentic AI is clear, its robust and scalable
deployment hinges on addressing several key research areas:
\begin{itemize}
            \item \textbf{Standardization of engineering tool integration:} As highlighted in the power systems case study, the lack of official standardized Model Context Protocols (MCPs) from engineering software vendors such as \textit{PSS®E,
PowerWorld, CDEGS} is a major barrier for standardized deployment.
Future research must focus on developing open, stable, and secure
standards for agent-tool interaction to ensure interoperability, reliability, and
foster a collaborative development ecosystem.
            \item \textbf{Scalability for large-scale engineering data:} Our case studies revealed performance limitations when dealing with large network files where token
limits got invoked and complex 3D models where we ran into memory
constraints. Future work is needed to design agentic architectures that can
efficiently process and reason over massive, domain-specific datasets. This
solution in this direction could involve research into advanced data
chunking and specialized agent models.
            \item \textbf{Enhancing agentic reasoning and accuracy:} The RFQ-to-BoQ case
study demonstrated that while agents can automate workflows, achieving
high accuracy in complex estimation tasks remains a challenge. Future
research should focus on improving the reasoning, validation, and
estimation capabilities of agents, potentially through domain-specific fine-
tuning, more sophisticated RAG techniques, or tighter integration of
symbolic reasoning engines.
            \item \textbf{Empirical validation of security frameworks:} The ZTF and information
clustering architectures proposed in this paper are, at present, conceptual.
A critical next step is the empirical validation and benchmarking of these
(and other) security frameworks against sophisticated adversarial attacks to
quantify their effectiveness, robustness, and computational overhead in
real-world scenarios.
\end{itemize}

By focusing on these areas, the research community can pave the way for the
development of agentic AI systems that are not only powerful and autonomous but also
secure, reliable, and fundamentally trustworthy.


\section*{Author Contributions}

Conceptualization, S.G. and G.M.; methodology, S.G.; software, S.G. and
G.M.; validation, S.G. and G.M.; formal analysis, S.G. and G.M.; resources, S.G.; data curation,
S.G. and G.M.; writing—original draft preparation, S.G. and G.M.; writing—review and editing,
S.G. and G.M.; visualization, S.G.; supervision, S.G.

The views, thoughts, opinions, and conclusions made in this manuscript are solely those of
the authors and not their employer. The authors are solely responsible for the content and
accuracy of the technical manuscript. The authors have read and agreed to the published version
of the manuscript.

\section*{Funding}

This research received no external funding. This work was independently conducted
and self-funded by the authors.

\section*{Data Availability Statement}

The original contributions presented in this study are included in the
article. Further inquiries can be directed to the corresponding author.

\section*{Acknowledgments}

The authors would like to thank Siddharth Ahuja for his contribution in
developing the Blender MCP and making it available in Github. The authors would thank Qian
Zhang, Muhy Eddin Za’ter, and Maanas Goel for their important work in developing several of the
power system simulation software MCPs, including the pandapower MCP, and making these
MCPs available in Github. The authors would like to thank Sreejata Dutta, Biostatistician at
Children's Hospitals Association for sharing her expertise in survival analysis and related theory.

\section*{Conflicts of Interest}
The authors declares that the research was conducted in the absence of
any commercial or financial relationships that could be construed as a potential conflict of interest.




\bibliographystyle{unsrtnat}
\bibliography{references}  %%% Uncomment this line and comment out the ``thebibliography'' section below to use the external .bib file (using bibtex) .


%%% Uncomment this section and comment out the \bibliography{references} line above to use inline references.
% \begin{thebibliography}{1}

% 	\bibitem{kour2014real}
% 	George Kour and Raid Saabne.
% 	\newblock Real-time segmentation of on-line handwritten arabic script.
% 	\newblock In {\em Frontiers in Handwriting Recognition (ICFHR), 2014 14th
% 			International Conference on}, pages 417--422. IEEE, 2014.

% 	\bibitem{kour2014fast}
% 	George Kour and Raid Saabne.
% 	\newblock Fast classification of handwritten on-line arabic characters.
% 	\newblock In {\em Soft Computing and Pattern Recognition (SoCPaR), 2014 6th
% 			International Conference of}, pages 312--318. IEEE, 2014.

% 	\bibitem{hadash2018estimate}
% 	Guy Hadash, Einat Kermany, Boaz Carmeli, Ofer Lavi, George Kour, and Alon
% 	Jacovi.
% 	\newblock Estimate and replace: A novel approach to integrating deep neural
% 	networks with existing applications.
% 	\newblock {\em arXiv preprint arXiv:1804.09028}, 2018.

% \end{thebibliography}


\end{document}
