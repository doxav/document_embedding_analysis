@article{ahlgren2025assisting,
  title={Assisting early-stage software startups with LLMs: Effective prompt engineering and system instruction design},
  author={Ahlgren, Thea Lovise and Sunde, Helene F{\o}nstelien and Kemell, Kai-Kristian and Nguyen-Duc, Anh},
  journal={Information and Software Technology},
  pages={107832},
  year={2025},
  publisher={Elsevier}
}

@article{alhanahnah2025empirical,
  title={An empirical evaluation of pre-trained large language models for repairing declarative formal specifications},
  author={Alhanahnah, Mohannad and Rashedul Hasan, Md and Xu, Lisong and Bagheri, Hamid},
  journal={Empirical Software Engineering},
  volume={30},
  number={5},
  pages={1--38},
  year={2025},
  publisher={Springer}
}

@article{alharbi2026automatic,
  title={Automatic Code Generation Techniques: A Systematic Literature Review},
  author={Alharbi, Maha and Alshayeb, Mohammad},
  journal={Automated Software Engineering},
  volume={33},
  number={1},
  pages={4},
  year={2026},
  publisher={Springer}
}

@inproceedings{chen2025evaluating,
  title={Evaluating software development agents: Patch patterns, code quality, and issue complexity in real-world github scenarios},
  author={Chen, Zhi and Jiang, Lingxiao},
  booktitle={2025 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  pages={657--668},
  year={2025},
  organization={IEEE}
}

@article{cruz2025prompt,
  title={Prompt engineering and framework: implementation to increase code reliability based guideline for LLMs},
  author={Cruz, Rogelio and Contreras, Jonatan and Guerrero, Francisco and Rodriguez, Ezequiel and Valdez, Carlos and Carrillo, Citlali},
  journal={arXiv preprint arXiv:2506.10989},
  year={2025}
}

@article{dakhel2024effective,
  title={Effective test generation using pre-trained large language models and mutation testing},
  author={Dakhel, Arghavan Moradi and Nikanjam, Amin and Majdinasab, Vahid and Khomh, Foutse and Desmarais, Michel C},
  journal={Information and Software Technology},
  volume={171},
  pages={107468},
  year={2024},
  publisher={Elsevier}
}

@article{della2025prompt,
  title={Do Prompt Patterns Affect Code Quality? A First Empirical Assessment of ChatGPT-Generated Code},
  author={Della Porta, Antonio and Lambiase, Stefano and Palomba, Fabio},
  journal={arXiv preprint arXiv:2504.13656},
  year={2025}
}

@inproceedings{fagadau2024analyzing,
  title={Analyzing prompt influence on automated method generation: An empirical study with copilot},
  author={Fagadau, Ionut Daniel and Mariani, Leonardo and Micucci, Daniela and Riganelli, Oliviero},
  booktitle={Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
  pages={24--34},
  year={2024}
}

@article{hao2024empirical,
  title={An empirical study on developers’ shared conversations with ChatGPT in GitHub pull requests and issues},
  author={Hao, Huizi and Hasan, Kazi Amit and Qin, Hong and Macedo, Marcos and Tian, Yuan and Ding, Steven HH and Hassan, Ahmed E},
  journal={Empirical Software Engineering},
  volume={29},
  number={6},
  pages={150},
  year={2024},
  publisher={Springer}
}

@article{he2026enhancing,
  title={Enhancing the ability of LLMs for spaceborne equipment code generation via retrieval-augmented generation and contrastive learning},
  author={He, Rui and Zhang, Liang and Lyu, Liangqing and Xue, Changbin},
  journal={Automated Software Engineering},
  volume={33},
  number={1},
  pages={1--25},
  year={2026},
  publisher={Springer}
}

@article{hwang2025llms,
  title={Llms can be easily confused by instructional distractions},
  author={Hwang, Yerin and Kim, Yongil and Koo, Jahyun and Kang, Taegwan and Bae, Hyunkyung and Jung, Kyomin},
  journal={arXiv preprint arXiv:2502.04362},
  year={2025}
}

@article{khojah2025impact,
  title={The impact of prompt programming on function-level code generation},
  author={Khojah, Ranim and de Oliveira Neto, Francisco Gomes and Mohamad, Mazen and Leitner, Philipp},
  journal={IEEE Transactions on Software Engineering},
  year={2025},
  publisher={IEEE}
}

@article{laban2025llms,
  title={Llms get lost in multi-turn conversation},
  author={Laban, Philippe and Hayashi, Hiroaki and Zhou, Yingbo and Neville, Jennifer},
  journal={arXiv preprint arXiv:2505.06120},
  year={2025}
}

@article{le2024rethinking,
  title={Rethinking AI code generation: a one-shot correction approach based on user feedback},
  author={Le, Kim Tuyen and Andrzejak, Artur},
  journal={Automated Software Engineering},
  volume={31},
  number={2},
  pages={60},
  year={2024},
  publisher={Springer}
}

@article{li2025beyond,
  title={Beyond single-turn: A survey on multi-turn interactions with large language models},
  author={Li, Yubo and Shen, Xiaobin and Yao, Xinyu and Ding, Xueying and Miao, Yidi and Krishnan, Ramayya and Padman, Rema},
  journal={arXiv preprint arXiv:2504.04717},
  year={2025a}
}

@article{li2025context,
  title={Context-aware prompting for LLM-based program repair},
  author={Li, Yingling and Cai, Muxin and Chen, Junjie and Xu, Yang and Huang, Lei and Li, Jianping},
  journal={Automated Software Engineering},
  volume={32},
  number={2},
  pages={42},
  year={2025b},
  publisher={Springer}
}

@article{liu2024lost,
  title={Lost in the middle: How language models use long contexts},
  author={Liu, Nelson F and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={157--173},
  year={2024}
}

@article{lou2024large,
  title={Large language model instruction following: A survey of progresses and challenges},
  author={Lou, Renze and Zhang, Kai and Yin, Wenpeng},
  journal={Computational Linguistics},
  volume={50},
  number={3},
  pages={1053--1095},
  year={2024},
  publisher={MIT Press 255 Main Street, 9th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{min2022rethinking,
  title={Rethinking the role of demonstrations: What makes in-context learning work?},
  author={Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2202.12837},
  year={2022}
}

@article{mizrahi2024state,
  title={State of what art? a call for multi-prompt llm evaluation},
  author={Mizrahi, Moran and Kaplan, Guy and Malkin, Dan and Dror, Rotem and Shahaf, Dafna and Stanovsky, Gabriel},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={933--949},
  year={2024},
  publisher={MIT Press 255 Main Street, 9th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@inproceedings{niu2024evaluating,
  title={On evaluating the efficiency of source code generated by llms},
  author={Niu, Changan and Zhang, Ting and Li, Chuanyi and Luo, Bin and Ng, Vincent},
  booktitle={Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
  pages={103--107},
  year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{pandey2025design,
  title={Design pattern recognition: a study of large language models},
  author={Pandey, Sushant Kumar and Chand, Sivajeet and Horkoff, Jennifer and Staron, Miroslaw and Ochodek, Miroslaw and Durisic, Darko},
  journal={Empirical Software Engineering},
  volume={30},
  number={3},
  pages={69},
  year={2025},
  publisher={Springer}
}

@article{perez2021true,
  title={True few-shot learning with language models},
  author={Perez, Ethan and Kiela, Douwe and Cho, Kyunghyun},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={11054--11070},
  year={2021}
}

@article{qin2024infobench,
  title={Infobench: Evaluating instruction following ability in large language models},
  author={Qin, Yiwei and Song, Kaiqiang and Hu, Yebowen and Yao, Wenlin and Cho, Sangwoo and Wang, Xiaoyang and Wu, Xuansheng and Liu, Fei and Liu, Pengfei and Yu, Dong},
  journal={arXiv preprint arXiv:2401.03601},
  year={2024}
}

@article{qu2025badcodeprompt,
  title={BadCodePrompt: backdoor attacks against prompt engineering of large language models for code generation},
  author={Qu, Yubin and Huang, Song and Li, Yanzhou and Bai, Tongtong and Chen, Xiang and Wang, Xingya and Li, Long and Yao, Yongming},
  journal={Automated Software Engineering},
  volume={32},
  number={1},
  pages={17},
  year={2025},
  publisher={Springer}
}

@article{quan2025evaluation,
  title={Evaluation and Improvement of Test Selection for Large Language Models},
  author={Quan, Lili and Wen, Jin and Hu, Qiang and Cordy, Maxime and Huang, Yuheng and Ma, Lei and Li, Xiaohong},
  journal={Journal of Software: Evolution and Process},
  volume={37},
  number={10},
  pages={e70057},
  year={2025},
  publisher={Wiley Online Library}
}

@article{saito2023verbosity,
  title={Verbosity bias in preference labeling by large language models},
  author={Saito, Keita and Wachi, Akifumi and Wataoka, Koki and Akimoto, Youhei},
  journal={arXiv preprint arXiv:2310.10076},
  year={2023}
}

@article{sarkar2025ai,
  title={AI Agents, Productivity, and Higher-Order Thinking: Early Evidence From Software Development},
  author={Sarkar, Suproteem K},
  journal={Available at SSRN 5713646},
  year={2025}
}

@article{sauvola2024future,
  title={Future of software development with generative AI},
  author={Sauvola, Jaakko and Tarkoma, Sasu and Klemettinen, Mika and Riekki, Jukka and Doermann, David},
  journal={Automated Software Engineering},
  volume={31},
  number={1},
  pages={26},
  year={2024},
  publisher={Springer}
}

@article{sergeyuk2025using,
  title={Using AI-based coding assistants in practice: State of affairs, perceptions, and ways forward},
  author={Sergeyuk, Agnia and Golubev, Yaroslav and Bryksin, Timofey and Ahmed, Iftekhar},
  journal={Information and Software Technology},
  volume={178},
  pages={107610},
  year={2025},
  publisher={Elsevier}
}

@article{shinn2023reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={8634--8652},
  year={2023}
}

@article{sirdeshmukh2025multichallenge,
  title={Multichallenge: A realistic multi-turn conversation evaluation benchmark challenging to frontier llms},
  author={Sirdeshmukh, Ved and Deshpande, Kaustubh and Mols, Johannes and Jin, Lifeng and Cardona, Ed-Yeremai and Lee, Dean and Kritz, Jeremy and Primack, Willow and Yue, Summer and Xing, Chen},
  journal={arXiv preprint arXiv:2501.17399},
  year={2025}
}

@article{sun2023principle,
  title={Principle-driven self-alignment of language models from scratch with minimal human supervision},
  author={Sun, Zhiqing and Shen, Yikang and Zhou, Qinhong and Zhang, Hongxin and Chen, Zhenfang and Cox, David and Yang, Yiming and Gan, Chuang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={2511--2565},
  year={2023}
}

@article{tambon2025bugs,
  title={Bugs in large language models generated code: An empirical study},
  author={Tambon, Florian and Moradi-Dakhel, Arghavan and Nikanjam, Amin and Khomh, Foutse and Desmarais, Michel C and Antoniol, Giuliano},
  journal={Empirical Software Engineering},
  volume={30},
  number={3},
  pages={65},
  year={2025},
  publisher={Springer}
}

@article{wang2025beyond,
  title={Beyond functional correctness: Investigating coding style inconsistencies in large language models},
  author={Wang, Yanlin and Jiang, Tianyue and Liu, Mingwei and Chen, Jiachi and Mao, Mingzhi and Liu, Xilin and Ma, Yuchi and Zheng, Zibin},
  journal={Proceedings of the ACM on Software Engineering},
  volume={2},
  number={FSE},
  pages={690--712},
  year={2025a},
  publisher={ACM New York, NY, USA}
}

@article{wang2025agents,
  title={Agents in software engineering: Survey, landscape, and vision},
  author={Wang, Yanlin and Zhong, Wanjun and Huang, Yanxian and Shi, Ensheng and Yang, Min and Chen, Jiachi and Li, Hui and Ma, Yuchi and Wang, Qianxiang and Zheng, Zibin},
  journal={Automated Software Engineering},
  volume={32},
  number={2},
  pages={1--36},
  year={2025b},
  publisher={Springer}
}

@article{xu2024does,
  title={Does Few-Shot Learning Help LLM Performance in Code Synthesis?},
  author={Xu, Derek and Xie, Tong and Xia, Botao and Li, Haoyu and Bai, Yunsheng and Sun, Yizhou and Wang, Wei},
  journal={arXiv preprint arXiv:2412.02906},
  year={2024}
}

@article{xu2025code_transformed,
  title={code\_transformed: The Influence of Large Language Models on Code},
  author={Xu, Yuliang and Huang, Siming and Geng, Mingmeng and Wan, Yao and Shi, Xuanhua and Chen, Dongping},
  journal={arXiv preprint arXiv:2506.12014},
  year={2025}
}

@article{yuan2025ui2html,
  title={UI2HTML: utilizing LLM agents with chain of thought to convert UI into HTML code},
  author={Yuan, Dawei and Yang, Guocang and Zhang, Tao},
  journal={Automated Software Engineering},
  volume={32},
  number={2},
  pages={1--24},
  year={2025},
  publisher={Springer}
}

@article{zhang2026brmds,
  title={BRMDS: an LLM-based multi-dimensional summary generation approach for bug reports},
  author={Zhang, Yayun and Li, Yuying and Fang, Minying and Yuan, Xing and Du, Junwei},
  journal={Automated Software Engineering},
  volume={33},
  number={1},
  pages={1--40},
  year={2026},
  publisher={Springer}
}

@article{zheng2025towards,
  title={Towards an understanding of large language models in software engineering tasks},
  author={Zheng, Zibin and Ning, Kaiwen and Zhong, Qingyuan and Chen, Jiachi and Chen, Wenqing and Guo, Lianghong and Wang, Weicheng and Wang, Yanlin},
  journal={Empirical Software Engineering},
  volume={30},
  number={2},
  pages={50},
  year={2025},
  publisher={Springer}
}

