@inproceedings{zhang2011coordinated,
  title={Coordinated multi-agent reinforcement learning in networked distributed POMDPs},
  author={Zhang, Chongjie and Lesser, Victor},
  booktitle={Proc. AAAI Conf. Artif. Intell.},
  volume={25},
  number={1},
  pages={764--770},
  year={2011}
}

@article{huttenrauch2017guided,
  title={Guided deep reinforcement learning for swarm systems},
  author = {H{\"u}ttenrauch, Maximilian and {\v{S}}o{\v{s}}i{\'c}, Adrian and Neumann, Gerhard},
  journal={arXiv preprint arXiv:1709.06011},
  year={2017}
}
@inproceedings{rombach2022high,
	title={High-resolution image synthesis with latent diffusion models},
	author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
        volume={2022},
	pages={10684--10695},
	year={2022}
}
@article{liu2025mixrts,
  title={{MIXRT}s: Toward interpretable multi-agent reinforcement learning via mixing recurrent soft decision trees},
  author={Liu, Zichuan and Zhu, Yuanyang and Wang, Zhi and Gao, Yang and Chen, Chunlin},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.},
  year={2025},
  volume={47},
  number={5},
  pages={4090-4107},
}
@inproceedings{liu23be,
  title = 	 {{N}$\text{{A}}^\text{2}${Q}: Neural Attention Additive Model for Interpretable Multi-Agent {Q}-Learning},
  author =       {Liu, Zichuan and Zhu, Yuanyang and Chen, Chunlin},
  booktitle = 	 {Proc. Int. Conf. Mach. Learn.},
  pages = 	 {22539--22558},
  year = 	 {2023},
  volume = 	 {202},
  publisher =    {PMLR}
}
@inproceedings{xuhigh,
  title={High-order Interactions Modeling for Interpretable Multi-Agent Q-Learning},
  author={Xu, Qinyu and Zhu, Yuanyang and Wu, Xuefei and Chen, Chunlin},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={38},
  year={2025}
}
@inproceedings{ma2024deepcache,
	title={Deepcache: Accelerating diffusion models for free},
	author={Ma, Xinyin and Fang, Gongfan and Wang, Xinchao},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={15762--15772},
	year={2024}
}

@inproceedings{christianos2021scaling,
	title={Scaling multi-agent reinforcement learning with selective parameter sharing},
	author={Christianos, Filippos and Papoudakis, Georgios and Rahman, Muhammad A and Albrecht, Stefano V},
	booktitle={Proc. Int. Conf. Mach. Learn.},
        volume={139},
	pages={1989--1998},
	year={2021}
}

@inproceedings{li2022deconfounded,
  title={Deconfounded value decomposition for multi-agent reinforcement learning},
  author={Li, Jiahui and Kuang, Kun and Wang, Baoxiang and Liu, Furui and Chen, Long and Fan, Changjie and Wu, Fei and Xiao, Jun},
  booktitle = {Proc. Int. Conf. Mach. Learn.},
  volume = {162},
  pages={12843--12856},
  year={2022}
}

@article{zhu2024multi,
  title={Multi-Task Multi-Agent Reinforcement Learning With Task-Entity Transformers and Value Decomposition Training},
  author={Zhu, Yuanheng and Huang, Shangjing and Zuo, Binbin and Zhao, Dongbin and Sun, Changyin},
  journal={IEEE Transactions on Automation Science and Engineering},  
  year={2024},
  publisher={IEEE}
}

@article{wang2023asn,
  title={{ASN}: Action Semantics Network for Multiagent Reinforcement Learning},
  author={Wang, Weixun and Yang, Tianpei and Liu, Yong and Hao, Jianye and Hao, Xiaotian and Hu, Yujing and Chen, Yingfeng and Fan, Changjie and Gao, Yang},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={37},
  number={1},
  pages={1--28},
  year={2023},
  publisher={Springer}
}

@article{pham2018cooperative,
  title={Cooperative and distributed reinforcement learning of drones for field coverage},
  author={Pham, Huy Xuan and La, Hung Manh and Feil-Seifer, David and Nefian, Aria},
  journal={arXiv preprint arXiv:1803.07250},
  year={2018}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, Jürgen},
  journal={Neural Computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@inproceedings{tan1993multi,
  title={Multi-Agent Reinforcement Learning: Independent versus Cooperative Agents},
  author={Tan, Ming},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  year={1993},
  pages={330--337}
}

@article{oliehoek2008optimal,
  title={Optimal and approximate Q-value functions for decentralized POMDPs},
  author={Oliehoek, Frans A and Spaan, Matthijs TJ and Vlassis, Nikos},
  journal={J. Artif. Intell. Res.},
  volume={32},
  pages={289--353},
  year={2008}
}

@inproceedings{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  booktitle={Proceedings of the Deep Learning and Representation Learning Workshop, NeurIPS},
  year={2014},
}

@article{kraemer2016multi,
  title={Multi-agent reinforcement learning as a rehearsal for decentralized planning},
  author={Kraemer, Landon and Banerjee, Bikramjit},
  journal={Neurocomputing},
  volume={190},
  pages={82--94},
  year={2016},
  publisher={Elsevier}
}

@inproceedings{qmix,
  title = {{QMIX}: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning},
  author = {Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  booktitle = {Proc. Int. Conf. Mach. Learn.},
  pages = {4295--4304},
  year = {2018},
  volume = {80}
}

@inproceedings{vdn,
  title = {Value-Decomposition Networks For Cooperative Multi-Agent Learning},
  author = {Peter Sunehag and Guy Lever and Audrunas Gruslys and Wojciech Marian Czarnecki and Vinicius Zambaldi and Max Jaderberg and Marc Lanctot and Nicolas Sonnerat and Joel Z. Leibo and Karl Tuyls and Thore Graepel},
  booktitle = {Proc. Int. Conf. Auto. Agents Multiagent Syst.},
  pages = {2085--2087},
  year = {2018},
}

@inproceedings{qplex,
  title={{QPLEX}: Duplex Dueling Multi-Agent {Q}-Learning},
  author={Wang, Jianhao and Ren, Zhizhou and Liu, Terry and Yu, Yang and Zhang, Chongjie},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2021}
}


@inproceedings{parisotto2020stabilizing,
  title = {Stabilizing Transformers for Reinforcement Learning},
  author = {Parisotto, Emilio and Song, Francis and Rae, Jack and Pascanu, Razvan and Gulcehre, Caglar and Jayakumar, Siddhant and Jaderberg, Max and Lopez Kaufman, Raphaël and Clark, Aidan and Noury, Seb and Botvinick, Matthew and Heess, Nicolas and Hadsell, Raia},
  booktitle = {Proc. Int. Conf. Mach. Learn.},
  pages = {7487--7498},
  year = {2020},
  volume = {119}
}


@inproceedings{rashid2020weighted,
  title={Weighted QMIX: Expanding Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning},
  author={Rashid, Tabish and Farquhar, Gregory and Peng, Bei and Whiteson, Shimon},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={33},
  pages={10199--10210},
  year={2020}
}


@inproceedings{foerster2018counterfactual,
  title={Counterfactual multi-agent policy gradients},
  author = {Jakob Foerster and Gregory Farquhar and Triantafyllos Afouras and Nantas Nardelli and Shimon Whiteson},
  booktitle={Proc. AAAI Conf. Artif. Intell.},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{yang2022transformer,
  title={Transformer-based Working Memory for Multiagent Reinforcement Learning with Action Parsing},
  author={Yaodong Yang and Guangyong Chen and Weixun Wang and Xiaotian Hao and Jianye Hao and Pheng-Ann Heng},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={35},
  pages={1--14},
  year={2022}
}

@inproceedings{qtran,
  title={QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning},
  author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David and Yi, Yung},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  volume={97},
  pages={5887--5896},
  year={2019}
}

@inproceedings{mat,
  title={Multi-Agent Reinforcement Learning is a Sequence Modeling Problem},
  author={Muning Wen and Jakub Grudzien Kuba and Runji Lin and Weinan Zhang and Ying Wen and Jun Wang and Yaodong Yang},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={35},
  pages={24602--24616},
  year={2022}
}

@book{smith1776wealth,
  title={An Inquiry into the Nature and Causes of the Wealth of Nations},
  author={Adam Smith},
  year={1776},
  publisher={W. Strahan and T. Cadell},
}

@book{butler2011condensed,
  title = {The Condensed Wealth of Nations},
  author = {Eamonn Butler},
  year = {2011},
  publisher = {Adam Smith Institute},
}


@inproceedings{wang2020roma,
  title={ROMA: Multi-Agent Reinforcement Learning with Emergent Roles},
  author={Wang, Tonghan and Dong, Heng and Lesser, Victor and Zhang, Chongjie},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  volume={119},
  pages={9876--9886},
  year={2020}
}


@inproceedings{wang2021rode,
  title={{RODE}: Learning Roles to Decompose Multi-Agent Tasks},
  author={Wang, Tonghan and Gupta, Tarun and Mahajan, Anuj and Peng, Bei and Whiteson, Shimon and Zhang, Chongjie},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2021}
}



@inproceedings{li2021celebrating,
  title={Celebrating Diversity in Shared Multi-Agent Reinforcement Learning},
  author={Li, Chenghao and Wang, Tonghan and Wu, Chengjie and Zhao, Qianchuan and Yang, Jun and Zhang, Chongjie},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={34},
  pages={20888--20900},
  year={2021}
}

@inproceedings{liu2022heterogeneous,
  title={Heterogeneous Skill Learning for Multi-agent Tasks},
  author={Liu, Yuntao and Li, Yuan and Xu, Xinhai and Dou, Yong and Liu, Donghong},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={35},
  pages={26412--26425},
  year={2022}
}

@inproceedings{yang2022ldsa,
  title={{LDSA}: Learning Dynamic Subtask Assignment in Cooperative Multi-Agent Reinforcement Learning},
  author={Yang, Mingyu and Zhao, Jian and Hu, Xunhan and Zhou, Wengang and Zhu, Jiangcheng and Li, Houqiang},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={35},
  pages={11735--11743},
  year={2022}
}


@book{oliehoek2016concise,
  title={A Concise Introduction to Decentralized POMDPs},
  author={Oliehoek, Frans A. and Amato, Christopher},
  year={2016},
  publisher={Springer}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author = {Richard S Sutton and Andrew G Barto},
  year={2018},
  publisher={MIT press}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Andrei A Rusu and Joel Veness and Marc G Bellemare and Alex Graves and Martin Riedmiller and Andreas K Fidjeland and Georg Ostrovski and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{ho2020denoising,
  title={Denoising Diffusion Probabilistic Models},
  author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{sohl2015deep,
  title={Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  author={Jascha Sohl-Dickstein and Eric Weiss and Niru Maheswaranathan and Surya Ganguli},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  pages={2256--2265},
  year={2015},
  volume={37}
}

@inproceedings{song2019generative,
  title={Generative Modeling by Estimating Gradients of the Data Distribution},
  author={Yang Song and Stefano Ermon},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={32},
  pages={11895--11907},
  year={2019}
}


@inproceedings{samvelyan2019starcraft,
  title={The StarCraft Multi-Agent Challenge},
  author={Samvelyan, Mikayel and Rashid, Tabish and de Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  booktitle={Proc. Int. Conf. Auto. Agents Multiagent Syst.},
  pages={2186--2188},
  year={2019}
}


@inproceedings{foerster2016learning,
  title={Learning to Communicate with Deep Multi-Agent Reinforcement Learning},
  author={Foerster, Jakob and Assael, Ioannis Alexandros and de Freitas, Nando and Whiteson, Shimon},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={29},
  pages={2137--2145},
  year={2016}
}


@inproceedings{wang2020learning,
  title={Learning Nearly Decomposable Value Functions via Communication Minimization},
  author={Wang, Tonghan and Wang, Jianhao and Zheng, Chongyi and Zhang, Chongjie},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2020}
}


@inproceedings{mahajan2019maven,
  title={{MAVEN}: Multi-Agent Variational Exploration},
  author={Mahajan, Anuj and Rashid, Tabish and Samvelyan, Mikayel and Whiteson, Shimon},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={32},
  pages={7611--7622},
  year={2019}
}


@inproceedings{gupta2021uneven,
  title={{UneVEn}: Universal Value Exploration for Multi-Agent Reinforcement Learning},
  author={Gupta, Tarun and Mahajan, Anuj and Peng, Bei and B{\"o}hmer, Wendelin and Whiteson, Shimon},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  volume={139},
  pages={3930--3941},
  year={2021}
}


@inproceedings{zhang2020robust,
  title={Robust multi-agent reinforcement learning with model uncertainty},
  author = {Kaiqing Zhang and Tao Sun and Yunzhe Tao and Sahika Genc and Sunil Mallya and Tamer Basar},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={33},
  pages={10571--10583},
  year={2020}
}

@article{zhao2022coach,
  title={Coach-assisted multi-agent reinforcement learning framework for unexpected crashed agents},
  author = {Jian Zhao and Youpeng Zhao and Weixun Wang and Mingyu Yang and Xunhan Hu and Wengang Zhou and Jianye Hao and Houqiang Li},
  journal={Frontiers of Information Technology \& Electronic Engineering},
  volume={23},
  number={7},
  pages={1032--1042},
  year={2022},
  publisher={Springer}
}

@inproceedings{kingma2014auto,
  title={Auto-Encoding Variational Bayes},
  author={Kingma, Diederik P. and Welling, Max},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2014}
}


@inproceedings{jang2017categorical,
  title={Categorical Reparameterization with Gumbel-Softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2017}
}


@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author = {Richard S Sutton and Doina Precup and Satinder Singh},
  journal={Artif. Intell.},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@article{al2015hierarchical,
  title={Hierarchical reinforcement learning: a survey},
  author={Al-Emran, Mostafa},
  journal={International Journal of Computing and Digital Systems},
  volume={4},
  number={2},
  pages={137--143},
  year={2015},
  publisher={University of Bahrain}
}

@inproceedings{levy2019learning,
  title={Learning Multi-Level Hierarchies with Hindsight},
  author={Levy, Andrew and Konidaris, George and Platt, Robert and Saenko, Kate},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2019}
}


@inproceedings{sukhbaatar2018learning,
  title={Learning Goal Embeddings via Self-Play for Hierarchical Reinforcement Learning},
  author={Sukhbaatar, Sainbayar and Denton, Emily and Szlam, Arthur and Fergus, Rob},
  booktitle={Deep RL Workshop at NeurIPS 2018},
  year={2018}
}


@article{dwiel2019hierarchical,
  title={Hierarchical Policy Learning is Sensitive to Goal Space Design},
  author={Dwiel, Zach and Candadai, Madhavun and Phielipp, Mariano and Bansal, Arjun K},
  journal={arXiv preprint arXiv:1905.01537},
  year={2019}
}


@inproceedings{nair2020hierarchical,
  title={Hierarchical Foresight: Self-Supervised Learning of Long-Horizon Tasks via Visual Subgoal Generation},
  author={Nair, Suraj and Finn, Chelsea},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2020}
}


@article{dilokthanakul2019feature,
  title={Feature control as intrinsic motivation for hierarchical reinforcement learning},
  author = {Nat Dilokthanakul and Christos Kaplanis and Nick Pawlowski and Murray Shanahan},
  journal={IEEE Trans. Neural Netw. Learn. Syst.},
  volume={30},
  number={11},
  pages={3409--3418},
  year={2019},
  publisher={IEEE}
}

@article{daniel2016hierarchical,
  title={Hierarchical Relative Entropy Policy Search},
  author={Daniel, Christian and Neumann, Gerhard and Kroemer, Oliver and Peters, Jan},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={93},
  pages={1--50},
  year={2016},
  publisher={Microtome Publishing}
}

@inproceedings{warde2019unsupervised,
  title={Unsupervised Control Through Non-Parametric Discriminative Rewards},
  author={Warde-Farley, David and Van de Wiele, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Mnih, Volodymyr},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2019}
}


@inproceedings{shankar2020learning,
  title={Learning Robot Skills with Temporal Variational Inference},
  author={Shankar, Tanmay and Gupta, Abhinav},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  volume={119},
  pages={8624--8633},
  year={2020}
}


@inproceedings{sharma2020dynamics,
  title={Dynamics-Aware Unsupervised Discovery of Skills},
  author={Sharma, Archit and Gu, Shixiang and Levine, Sergey and Kumar, Vikash and Hausman, Karol},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2020}
}


@article{ossenkopf2019does,
  title={When does communication learning need hierarchical multi-agent deep reinforcement learning},
  author = {Marie Ossenkopf and Mackenzie Jorgensen and Kurt Geihs},
  journal={Cybernetics and Systems},
  volume={50},
  number={8},
  pages={672--692},
  year={2019},
  publisher={Taylor \& Francis}
}

@inproceedings{zhang2010self,
  title={Self-Organization for Coordinating Decentralized Reinforcement Learning},
  author={Zhang, Chongjie and Lesser, Victor R. and Abdallah, Sherief},
  booktitle={Proc. Int. Conf. Auto. Agents Multiagent Syst.},
  pages={739--746},
  year={2010}
}

@inproceedings{dayan1992feudal,
  title={Feudal Reinforcement Learning},
  author={Dayan, Peter and Hinton, Geoffrey E.},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={5},
  pages={271--278},
  year={1992}
}

@inproceedings{lee2020learning,
  title={Learning to Coordinate Manipulation Skills via Skill Behavior Diversification},
  author={Lee, Youngwoon and Yang, Jingyun and Lim, Joseph J.},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2020}
}


@inproceedings{yang2020hierarchical,
  title={Hierarchical Cooperative Multi-Agent Reinforcement Learning with Skill Discovery},
  author={Yang, Jiachen and Borovikov, Igor and Zha, Hongyuan},
  booktitle={Proc. Int. Conf. Auto. Agents Multiagent Syst.},
  pages={1566--1574},
  year={2020}
}


@inproceedings{vezhnevets2020options,
  title={OPtions as REsponses: Grounding Behavioural Hierarchies in Multi-Agent Reinforcement Learning},
  author={Vezhnevets, Alexander Sasha and Wu, Yuhuai and Eckstein, Maria and Leblond, Remi and Leibo, Joel Z.},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  pages={9733--9742},
  year={2020}
}

@inproceedings{song2021score,
  title={Score-Based Generative Modeling through Stochastic Differential Equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P. and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2021}
}

@inproceedings{janner2022planning,
  title={Planning with Diffusion for Flexible Behavior Synthesis},
  author={Janner, Michael and Du, Yilun and Tenenbaum, Joshua B. and Levine, Sergey},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  volume={162},
  pages={9902--9915},
  year={2022}
}

@inproceedings{wang2023diffusion,
  title={Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning},
  author={Wang, Zhendong and Hunt, Jonathan J. and Zhou, Mingyuan},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2023}
}


@inproceedings{lu2023synthetic,
  title={Synthetic Experience Replay},
  author={Lu, Cong and Ball, Philip and Teh, Yee Whye and Parker-Holder, Jack},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={36},
  year={2023}
}


@inproceedings{venkatraman2024reasoning,
  title={Reasoning with Latent Diffusion in Offline Reinforcement Learning},
  author={Venkatraman, Siddarth and Khaitan, Shivesh and Akella, Ravi Tej and Dolan, John and Schneider, Jeff and Berseth, Glen},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2024}
}


@inproceedings{he2023diffusion,
  title={Diffusion Model is an Effective Planner and Data Synthesizer for Multi-Task Reinforcement Learning},
  author={He, Haoran and Bai, Chenjia and Xu, Kang and Yang, Zhuoran and Zhang, Weinan and Wang, Dong and Zhao, Bin and Li, Xuelong},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={36},
  pages={64896--64917},
  year={2023}
}


@inproceedings{hegde2023generating,
  title={Generating behaviorally diverse policies with latent diffusion models},
  author = {Shashank Hegde and Sumeet Batra and KR Zentner and Gaurav Sukhatme},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={36},
  pages={7541--7554},
  year={2023}
}

@article{zhang2024motiondiffuse,
  title={Motiondiffuse: Text-driven human motion generation with diffusion model},
  author={Zhang, Mingyuan and Cai, Zhongang and Pan, Liang and Hong, Fangzhou and Guo, Xinying and Yang, Lei and Liu, Ziwei},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.},
  year={2024},
  volume={46},
  number={6},
  pages={4115-4128},
  publisher={IEEE}
}

@inproceedings{zang2023automatic,
  title={Automatic Grouping for Efficient Cooperative Multi-Agent Reinforcement Learning},
  author={Zang, Yifan and He, Jinmin and Li, Kai and Fu, Haobo and Fu, Qiang and Xing, Junliang and Cheng, Jian},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={36},
  pages={64896--64917},
  year={2023}
}

@inproceedings{ellis2023smacv2,
  title={{SMACv2}: An Improved Benchmark for Cooperative Multi-Agent Reinforcement Learning},
  author={Ellis, Benjamin and Cook, Jonathan and Moalla, Skander and Samvelyan, Mikayel and Sun, Mingfei and Mahajan, Anuj and Foerster, Jakob N. and Whiteson, Shimon},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={36},
  year={2023}
}


@article{yang2020qatten,
  title={{Qatten}: A General Framework for Cooperative Multiagent Reinforcement Learning},
  author={Yang, Yaodong and Hao, Jianye and Liao, Ben and Shao, Kun and Chen, Guangyong and Liu, Wulong and Tang, Hongyao},
  journal={arXiv preprint arXiv:2002.03939},
  year={2020}
}


@inproceedings{NEURIPS2020_7967cc8e,
 author = {Filippos Christianos and Sch\"{a}fer, Lukas and Albrecht, Stefano},
 booktitle = {Proc. Adv. Neural Inf. Process. Syst.},
 pages = {10707--10717},
 title = {Shared experience actor-critic for multi-agent reinforcement learning},
 volume = {33},
 year = {2020}
}

@inproceedings{sohldickstein2015deepunsupervisedlearningusing,
  title={Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric A and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  volume={37},
  pages={2256--2265},
  year={2015}
}


@inproceedings{xu2023haven,
  title={{HAVEN}: Hierarchical Cooperative Multi-Agent Reinforcement Learning with Dual Coordination Mechanism},
  author={Xu, Zhiwei and Bai, Yunpeng and Zhang, Bin and Li, Dapeng and Fan, Guoliang},
  booktitle={Proc. AAAI Conf. Artif. Intell.},
  volume={37},
  number={10},
  pages={11735--11743},
  year={2023}
}

@inproceedings{hu2024attention,
  title={Attention-Guided Contrastive Role Representations for Multi-Agent Reinforcement Learning},
  author={Hu, Zican and Zhang, Zongzhang and Li, Huaxiong and Chen, Chunlin and Ding, Hongyu and Wang, Zhi},
  booktitle={Proc. Int. Conf. Learn. Represent.},
  year={2024},
}

@inproceedings{tian2023decompose,
  title={Decompose a Task into Generalizable Subtasks in Multi-Agent Reinforcement Learning},
  author={Tian, Zikang and Chen, Ruizhi and Hu, Xing and Li, Ling and Zhang, Rui and Wu, Fan and Peng, Shaohui and Guo, Jiaming and Du, Zidong and Guo, Qi and Chen, Yunji},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  pages={78514--78532},
  volume={36},
  year={2023}
}