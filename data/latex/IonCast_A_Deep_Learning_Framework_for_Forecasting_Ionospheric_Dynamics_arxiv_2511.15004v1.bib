@article{Lam2023,
    author = {Remi Lam  and Alvaro Sanchez-Gonzalez  and Matthew Willson  and Peter Wirnsberger  and Meire Fortunato  and Ferran Alet  and Suman Ravuri  and Timo Ewalds  and Zach Eaton-Rosen  and Weihua Hu  and Alexander Merose  and Stephan Hoyer  and George Holland  and Oriol Vinyals  and Jacklynn Stott  and Alexander Pritzel  and Shakir Mohamed  and Peter Battaglia },
    title = {Learning skillful medium-range global weather forecasting},
    journal = {Science},
    volume = {382},
    number = {6677},
    pages = {1416-1421},
    year = {2023},
    doi = {10.1126/science.adi2336},
    URL = {https://www.science.org/doi/abs/10.1126/science.adi2336},
    eprint = {https://www.science.org/doi/pdf/10.1126/science.adi2336},
    abstract = {Global medium-range weather forecasting is critical to decision-making across many social and economic domains. Traditional numerical weather prediction uses increased compute resources to improve forecast accuracy but does not directly use historical weather data to improve the underlying model. Here, we introduce GraphCast, a machine learning–based method trained directly from reanalysis data. It predicts hundreds of weather variables for the next 10 days at 0.25° resolution globally in under 1 minute. GraphCast significantly outperforms the most accurate operational deterministic systems on 90\% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclone tracking, atmospheric rivers, and extreme temperatures. GraphCast is a key advance in accurate and efficient weather forecasting and helps realize the promise of machine learning for modeling complex dynamical systems. The numerical models used to predict weather are large, complex, and computationally demanding and do not learn from past weather patterns. Lam et al. introduced a machine learning–based method that has been trained directly from reanalysis data of past atmospheric conditions. In this way, the authors were able to quickly predict hundreds of weather variables globally up to 10 days in advance and at high resolution. Their predictions were more accurate than those of traditional weather models in 90\% of tested cases and displayed better severe event prediction for tropical cyclones, atmospheric rivers, and extreme temperatures. —H. Jesse Smith Machine learning leads to better, faster, and cheaper weather forecasting.}
}

@misc{Bonev2025,
      title={FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale}, 
      author={Boris Bonev and Thorsten Kurth and Ankur Mahesh and Mauro Bisson and Jean Kossaifi and Karthik Kashinath and Anima Anandkumar and William D. Collins and Michael S. Pritchard and Alexander Keller},
      year={2025},
      eprint={2507.12144},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2507.12144}, 
}

@book{kelley2009,
  title={The Earth's ionosphere: Plasma physics and electrodynamics},
  author={Kelley, Michael C},
  volume={96},
  year={2009},
  publisher={Academic press}
}

@article{Berger2020,
  title={Flying through uncertainty},
  author={Berger, Thomas E and Holzinger, MJ and Sutton, EK and Thayer, JP},
  journal={Space Weather},
  volume={18},
  number={1},
  pages={e2019SW002373},
  year={2020},
  publisher={Wiley Online Library}
}

@article{Jakowski2011,
  title={Total electron content models and their use in ionosphere monitoring},
  author={Jakowski, Norbert and Mayer, C and Hoque, MM and Wilken, V},
  journal={Radio Science},
  volume={46},
  number={06},
  pages={1--11},
  year={2011},
  publisher={AGU}
}

@article{Mannucci1998,
  title={A global mapping technique for GPS-derived ionospheric total electron content measurements},
  author={Mannucci, AJ and Wilson, BD and Yuan, DN and Ho, CH and Lindqwister, UJ and Runge, TF},
  journal={Radio science},
  volume={33},
  number={3},
  pages={565--582},
  year={1998},
  publisher={AGU}
}

@misc{Wilson2021,
  title={A quarter century of wind spacecraft discoveries},
  author={Wilson III, Lynn B and Brosius, Alexandra L and Gopalswamy, Natchimuthuk and Nieves-Chinchilla, Teresa and Szabo, Adam and Hurley, Kevin and Phan, Tai and Kasper, Justin C and Lugaz, No{\'e} and Richardson, Ian G and others},
  year={2021},
  publisher={Wiley Online Library}
}

@inproceedings{Giorgini1996,
  title={JPL's on-line solar system data service},
  author={Giorgini, JD and Yeomans, DK and Chamberlin, AB and Chodas, PW and Jacobson, RA and Keesey, MS and Lieske, JH and Ostro, SJ and Standish, EM and Wimberly, RN},
  booktitle={AAS/Division for Planetary Sciences Meeting Abstracts\# 28},
  volume={28},
  pages={25--04},
  year={1996}
}

@article{Tobiska2012,
  title={Solar and geomagnetic indices for thermospheric density models},
  author={Tobiska, W Kent and Bowman, BR and Bouwer, SD},
  journal={COSPAR International Reference Atmosphere, edited by Rees D. and Tobiska WK},
  year={2012}
}

@article{Laundal2017,
  title={Magnetic coordinate systems},
  author={Laundal, Karl Magnus and Richmond, Arthur D},
  journal={Space science reviews},
  volume={206},
  number={1},
  pages={27--59},
  year={2017},
  publisher={Springer}
}

@ARTICLE{Matzka21,
       author = {{Matzka}, J. and {Stolle}, C. and {Yamazaki}, Y. and {Bronkalla}, O. and {Morschhauser}, A.},
        title = "{The Geomagnetic Kp Index and Derived Indices of Geomagnetic Activity}",
      journal = {Space Weather},
         year = 2021,
        month = may,
       volume = {19},
       number = {5},
          eid = {e2020SW002641},
        pages = {e2020SW002641},
          doi = {10.1029/2020SW002641},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2021SpWea..1902641M},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{Nishida1992,
  title={Geotail mission to explore earth's magnetotail},
  author={Nishida, A and Uesugi, K and Nakatani, I and Mukai, T and Fairfield, DH and Acuna, MH},
  journal={Eos, Transactions American Geophysical Union},
  volume={73},
  number={40},
  pages={425--429},
  year={1992},
  publisher={Wiley Online Library}
}

@article{Stone1998,
  title={The advanced composition explorer},
  author={Stone, Edward C and Frandsen, AM and Mewaldt, RA and Christian, ER and Margolies, D and Ormes, JF and Snow, F},
  journal={Space Science Reviews},
  volume={86},
  number={1},
  pages={1--22},
  year={1998},
  publisher={Springer}
}

@article{Bilitza2011,
  title={The international reference ionosphere today and in the future},
  author={Bilitza, Dieter and McKinnell, Lee-Anne and Reinisch, Bodo and Fuller-Rowell, Tim},
  journal={Journal of Geodesy},
  volume={85},
  number={12},
  pages={909--920},
  year={2011},
  publisher={Springer}
}

@misc{Smirnov2023,
  title={A novel neural network model of Earth’s topside ionosphere. Sci Rep 13: 1303},
  author={Smirnov, A and Shprits, Y and Prol, F and L{\"u}hr, H and Berrendorf, M and Zhelavskaya, I and Xiong, C},
  year={2023}
}

@article{Xiong2021,
  title={Long short-term memory neural network for ionospheric total electron content forecasting over China},
  author={Xiong, Pan and Zhai, Dulin and Long, Cheng and Zhou, Huiyu and Zhang, Xuemin and Shen, Xuhui},
  journal={Space Weather},
  volume={19},
  number={4},
  pages={e2020SW002706},
  year={2021},
  publisher={Wiley Online Library}
}

@article{Zhukov2021,
  title={GIMLi: Global Ionospheric total electron content model based on machine learning},
  author={Zhukov, Aleksei V and Yasyukevich, Yury V and Bykov, Aleksei E},
  journal={GPS Solutions},
  volume={25},
  number={1},
  pages={19},
  year={2021},
  publisher={Springer}
}

@article{Ridley2006,
  title={The global ionosphere--thermosphere model},
  author={Ridley, AJ and Deng, Yue and T{\'o}th, G},
  journal={Journal of Atmospheric and Solar-Terrestrial Physics},
  volume={68},
  number={8},
  pages={839--864},
  year={2006},
  publisher={Elsevier}
}

@article{Bilitza2017,
  title={International Reference Ionosphere 2016: From ionospheric climate to real-time weather predictions},
  author={Bilitza, Dieter and Altadill, David and Truhlik, Vladimir and Shubin, Valentin and Galkin, Ivan and Reinisch, Bodo and Huang, Xueqin},
  journal={Space weather},
  volume={15},
  number={2},
  pages={418--429},
  year={2017},
  publisher={Wiley Online Library}
}

@article{Bilitza2022,
  title={The International Reference Ionosphere model: A review and description of an ionospheric benchmark},
  author={Bilitza, Dieter and Pezzopane, Michael and Truhlik, Vladimir and Altadill, David and Reinisch, Bodo W and Pignalberi, Alessio},
  journal={Reviews of geophysics},
  volume={60},
  number={4},
  pages={e2022RG000792},
  year={2022},
  publisher={Wiley Online Library}
}

@article{Martire2024,
  title={The JPL-GIM algorithm and products: multi-GNSS high-rate global mapping of total electron content.},
  author={Martire, L{\'e}o and Runge, Thomas F and Meng, Xing and Krishnamoorthy, Siddharth and Vergados, Panagiotis and Mannucci, Anthony J and Verkhoglyadova, Olga P and Komj{\'a}thy, Attila and Moore, Angelyn W and Meyer, Robert F and others},
  journal={Journal of Geodesy},
  volume={98},
  number={5},
  year={2024}
}

@article{Tsunoda1988,
  title={High-latitude F region irregularities: A review and synthesis},
  author={Tsunoda, Roland T},
  journal={Reviews of Geophysics},
  volume={26},
  number={4},
  pages={719--760},
  year={1988},
  publisher={Wiley Online Library}
}

@ARTICLE{Kintner1976,
       author = {{Kintner}, P.~M., Jr.},
        title = "{Observations of velocity shear driven plasma turbulence}",
      journal = {Journal of Geophysical Research},
     keywords = {Convective Flow, Magnetohydrodynamic Stability, Plasma Turbulence, Satellite Observation, Shear Flow, Southern Hemisphere, Auroral Zones, Electrostatics, Elliptical Orbits, Hawkeye Satellites, Heos B Satellite, Magnetic Effects, Plasma Diagnostics, Power Spectra, Geophysics},
         year = 1976,
        month = oct,
       volume = {81},
       number = {A28},
        pages = {5114-5122},
          doi = {10.1029/JA081i028p05114},
       adsurl = {https://ui.adsabs.harvard.edu/abs/1976JGR....81.5114K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{Pulkkinen2017,
  author={Pulkkinen, Antti and Bernabeu, E and Thomson, A and Viljanen, A and Pirjola, R and Boteler, D and Eichner, J and Cilliers, PJ and Welling, D and Savani, NP and others},
  title={Geomagnetically induced currents: Science, engineering, and applications readiness},
  journal={Space weather},
  volume={15},
  number={7},
  pages={828--856},
  year={2017},
  publisher={Wiley Online Library}
}

@article{Kataoka2022,
  title={Unexpected space weather causing the reentry of 38 Starlink satellites in February 2022},
  author={Kataoka, Ryuho and Shiota, Daikou and Fujiwara, Hitoshi and Jin, Hidekatsu and Tao, Chihiro and Shinagawa, Hiroyuki and Miyoshi, Yasunobu},
  journal={Journal of Space Weather and Space Climate},
  volume={12},
  pages={41},
  year={2022},
  publisher={EDP Sciences}
}

@article{Hochreiter1997,
    author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
    title = {Long Short-Term Memory},
    journal = {Neural Computation},
    volume = {9},
    number = {8},
    pages = {1735-1780},
    year = {1997},
    month = {11},
    abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
    issn = {0899-7667},
    doi = {10.1162/neco.1997.9.8.1735},
    url = {https://doi.org/10.1162/neco.1997.9.8.1735},
    eprint = {https://direct.mit.edu/neco/article-pdf/9/8/1735/813796/neco.1997.9.8.1735.pdf},
}

@misc{jpld,
  title        = {Global Ionospheric Maps for Research -- JPLD Data Product},
  author       = {Verkhoglyadova, Olga and Meng, Xing},
  organization = {Jet Propulsion Laboratory, California Institute of Technology},
  year         = {2024},
  month        = apr,
  note         = {Last updated: 8 Apr 2024. Government sponsorship acknowledged.},
  howpublished = {\url{https://sideshow.jpl.nasa.gov/pub/iono_daily/gim_for_research/jpld/}},
  copyright    = {California Institute of Technology},
}

@misc{Rideout,
  title={The Open Madrigal Initiative},
  author={Rideout W., Cariglia K.},
  link={https://cedar.openmadrigal.org}
}

@misc{walsh2024,
      title={A Foundation Model for the Solar Dynamics Observatory}, 
      author={James Walsh and Daniel G. Gass and Raul Ramos Pollan and Paul J. Wright and Richard Galvez and Noah Kasmanoff and Jason Naradowsky and Anne Spalding and James Parr and Atılım Güneş Baydin},
      year={2024},
      eprint={2410.02530},
      archivePrefix={arXiv},
      primaryClass={astro-ph.SR},
      url={https://arxiv.org/abs/2410.02530}, 
}

@misc{physicsnemo,
author = {},
  title = {PhysicsNeMo | NVIDIA Developer},
  url = "https://developer.nvidia.com/physicsnemo",
month = {},
year = {},
  note = "[Online; accessed 2025-08-30]"
}

@article{liu2020,
author = {Liu, Lei and Zou, Shasha and Yao, Yibin and Wang, Zihan},
title = {Forecasting Global Ionospheric TEC Using Deep Learning Approach},
journal = {Space Weather},
volume = {18},
number = {11},
pages = {e2020SW002501},
doi = {https://doi.org/10.1029/2020SW002501},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2020SW002501},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2020SW002501},
note = {e2020SW002501 2020SW002501},
abstract = {Abstract Global ionospheric total electron content (TEC) maps are widely utilized in research regarding ionospheric physics and the associated space weather impacts, so there is a great interest in the community in short-term ionosphere TEC forecasting. In this study, the long short-term memory (LSTM) neural network (NN) is applied to forecast the 256 spherical harmonic (SH) coefficients that are traditionally used to construct global ionospheric maps (GIM). Multiple input data, including historical time series of the SH coefficients, solar extreme ultraviolet (EUV) flux, disturbance storm time (Dst) index, and hour of the day, are used in the developed LSTM NN model. Different combinations of the above parameters have been used in constructing the LSTM NN model, and it is found that the model using all four parameters performs the best. Then the best performing LSTM model is used to forecast the SH coefficients, and the global hourly TEC maps are reproduced using the 256 predicted SH coefficients. A comprehensive evaluation is carried out with respect to the CODE GIM TEC. Results show that the first/second hour TEC root mean square error (RMSE) is 1.27/2.20 TECU during storm time and 0.86/1.51 TECU during quiet time, so the developed model performs well during both quiet and storm times. Moreover, typical ionospheric structures, such as equatorial ionization anomaly (EIA) and storm-enhanced density (SED), are well reproduced in the predicted TEC maps during storm time. The developed model also shows competitive performance in predicting global TEC when compared to the persistence model and two empirical models (IRI-2016 and NeQuick-2).},
year = {2020}
}

@article{ren2023,
author = {Ren, Xiaodong and Yang, Pengxin and Mei, Dengkui and Liu, Hang and Xu, Guozhen and Dong, Yue},
title = {Global Ionospheric TEC Forecasting for Geomagnetic Storm Time Using a Deep Learning-Based Multi-Model Ensemble Method},
journal = {Space Weather},
volume = {21},
number = {3},
pages = {e2022SW003231},
keywords = {ionospheric prediction, model ensembling, geomagnetic storms, deep learning, machine learning},
doi = {https://doi.org/10.1029/2022SW003231},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2022SW003231},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2022SW003231},
note = {e2022SW003231 2022SW003231},
abstract = {Abstract In recent years, deep learning has been extensively used for ionospheric total electron content (TEC) prediction, and many models can yield promising prediction results, particularly under quiet conditions. Owing to the ionosphere's intricate and dramatic changes during geomagnetic storms, the high-reliable prediction of the storm-time ionospheric TEC remains a challenging problem. In this study, we developed a new deep learning-based multi-model ensemble method (DLMEM) to forecast geomagnetic storm-time ionospheric TEC that combines the Random Forest (RF) model, the Extreme Gradient Boosting (XGBoost) algorithm, and the Gated Recurrent Unit (GRU) network with the attention mechanism. Seven features in 170 geomagnetic storm events, including the three components Bx, By and Bz of interplanetary magnetic field (IMF), the Kp and Dst indices of geomagnetic activity data, the F10.7 index of solar activity data and global TEC data, were used for modeling. The test set results showed that the DLMEM model can reduce the root mean square errors (RMSE) by an average of 43.6\% in comparison to our previously presented model Ion-LSTM, especially during the recovery period of geomagnetic storms. Furthermore, compared to Ion-LSTM, the RMSE values of the low-, middle- and high-latitude single-station forecast TEC can be greatly decreased by 33\%, 53\% and 59\%, respectively. It was shown that the new model allows for more precise short-term global ionospheric forecasting during geomagnetic storms, enabling real-time monitoring of ionospheric changes.},
year = {2023}
}

@misc{wandb,
title = {Experiment Tracking with Weights and Biases},
year = {2020},
note = {Software available from wandb.com},
url={https://www.wandb.com/},
author = {Biewald, Lukas},
}


