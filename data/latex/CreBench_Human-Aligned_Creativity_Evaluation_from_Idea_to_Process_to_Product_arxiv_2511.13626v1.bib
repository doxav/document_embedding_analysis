@article{gpt4v,
  title={The dawn of lmms: Preliminary explorations with gpt-4v (ision)},
  author={Yang, Zhengyuan and Li, Linjie and Lin, Kevin and Wang, Jianfeng and Lin, Chung-Ching and Liu, Zicheng and Wang, Lijuan},
  journal={arXiv preprint arXiv:2309.17421},
  volume={9},
  number={1},
  pages={1},
  year={2023}
}
@article{qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}
@inproceedings{wu2024towards,
  title={Towards open-ended visual quality comparison},
  author={Wu, Haoning and Zhu, Hanwei and Zhang, Zicheng and Zhang, Erli and Chen, Chaofeng and Liao, Liang and Li, Chunyi and Wang, Annan and Sun, Wenxiu and Yan, Qiong and others},
  booktitle={European Conference on Computer Vision},
  pages={360--377},
  year={2024},
  organization={Springer}
}

@article{kim2024mdagents,
  title={Mdagents: An adaptive collaboration of llms for medical decision-making},
  author={Kim, Yubin and Park, Chanwoo and Jeong, Hyewon and Chan, Yik S and Xu, Xuhai and McDuff, Daniel and Lee, Hyeonhoon and Ghassemi, Marzyeh and Breazeal, Cynthia and Park, Hae W},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={79410--79452},
  year={2024}
}

@inproceedings{han2025video,
  title={Video-Bench: Human-Aligned Video Generation Benchmark},
  author={Han, Hui and Li, Siyuan and Chen, Jiaqi and Yuan, Yiwen and Wu, Yuling and Deng, Yufan and Leong, Chak Tou and Du, Hanwen and Fu, Junchen and Li, Youhua and others},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={18858--18868},
  year={2025}
}
@article{huang2025causality,
  title={A Causality-aware Paradigm for Evaluating Creativity of Multimodal Large Language Models},
  author={Huang, Zhongzhan and Zhong, Shanshan and Zhou, Pan and Gao, Shanghua and Zitnik, Marinka and Lin, Liang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2025},
  publisher={IEEE}
}
@article{zhao2025assessing,
  title={Assessing and understanding creativity in large language models},
  author={Zhao, Yunpu and Zhang, Rui and Li, Wenyi and Li, Ling},
  journal={Machine Intelligence Research},
  volume={22},
  number={3},
  pages={417--436},
  year={2025},
  publisher={Springer}
}
@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2425--2433},
  year={2015}
}

@article{lu2022learn,
  title={Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author={Lu, Pan and Mishra, Swaroop and Xia, Tanglin and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={2507--2521},
  year={2022}
}


@inproceedings{huang2024aesexpert,
  title={Aesexpert: Towards multi-modality foundation model for image aesthetics perception},
  author={Huang, Yipo and Sheng, Xiangfei and Yang, Zhichao and Yuan, Quan and Duan, Zhichao and Chen, Pengfei and Li, Leida and Lin, Weisi and Shi, Guangming},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={5911--5920},
  year={2024}
}
@inproceedings{ye2025assessing,
  title={Assessing the creativity of llms in proposing novel solutions to mathematical problems},
  author={Ye, Junyi and Gu, Jingyi and Zhao, Xinyun and Yin, Wenpeng and Wang, Guiling},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={39},
  number={24},
  pages={25687--25696},
  year={2025}
}

@article{brophy1998,
  title={Understanding, measuring, and enhancing individual creative problem-solving efforts},
  author={Brophy, Dennis R},
  journal={Creativity Research Journal},
  volume={11},
  number={2},
  pages={123--150},
  year={1998},
  publisher={Taylor \& Francis}
}

@article{urban2005assessing,
  title={Assessing creativity: The Test for Creative Thinking-Drawing Production (TCT-DP).},
  author={Urban, Klaus K},
  journal={International Education Journal},
  volume={6},
  number={2},
  pages={272--280},
  year={2005},
  publisher={ERIC}
}

@article{christensen2016dimensions,
  title={Dimensions of creative evaluation: Distinct design and reasoning strategies for aesthetic, functional and originality judgments},
  author={Christensen, Bo T and Ball, Linden J},
  journal={Design studies},
  volume={45},
  pages={116--136},
  year={2016},
  publisher={Elsevier}
}

@article{runco2012standard,
  title={The standard definition of creativity},
  author={Runco, Mark A and Jaeger, Garrett J},
  journal={Creativity research journal},
  volume={24},
  number={1},
  pages={92--96},
  year={2012},
  publisher={Taylor \& Francis}
}

@article{judgments,
  title={Judgments of originality and appropriateness as predictors of creativity},
  author={Runco, Mark A and Charles, Robyn E},
  journal={Personality and individual differences},
  volume={15},
  number={5},
  pages={537--546},
  year={1993},
  publisher={Elsevier}
}

@book{wallas1926art,
  title={The art of thought},
  author={Wallas, Graham},
  number={24},
  year={1926},
  publisher={Harcourt, Brace}
}

@article{joy1950guilford,
  title={Guilford. 1950. Creativity},
  author={Joy, P},
  journal={American Psychologist},
  volume={5},
  number={9},
  pages={444--454},
  year={1950}
}

@article{okada2017imitation,
  title={Imitation, inspiration, and creation: Cognitive process of creative drawing by copying others' artworks},
  author={Okada, Takeshi and Ishibashi, Kentaro},
  journal={Cognitive science},
  volume={41},
  number={7},
  pages={1804--1837},
  year={2017},
  publisher={Wiley Online Library}
}

@incollection{Creativethinking,
  title={Creative thinking: Processes, strategies and knowledge},
  author={Mumford, Michael D and Giorgini, Vincent and Gibson, Carter and Mecca, Jensen},
  booktitle={Handbook of research on creativity},
  pages={249--264},
  year={2013},
  publisher={Edward Elgar Publishing}
}

@article{torrance1966torrance,
  title={Torrance tests of creative thinking},
  author={Torrance, E Paul},
  journal={Educational and psychological measurement},
  year={1966}
}

@article{charyton2011assessing,
  title={Assessing creativity specific to engineering with the revised creative engineering design assessment},
  author={Charyton, Christine and Jagacinski, Richard J and Merrill, John A and Clifton, William and DeDios, Samantha},
  journal={Journal of Engineering Education},
  volume={100},
  number={4},
  pages={778--799},
  year={2011},
  publisher={Wiley Online Library}
}

@article{howard2008describing,
  title={Describing the creative design process by the integration of engineering design and cognitive psychology literature},
  author={Howard, Thomas J and Culley, Stephen J and Dekoninck, Elies},
  journal={Design studies},
  volume={29},
  number={2},
  pages={160--180},
  year={2008},
  publisher={Elsevier}
}

@misc{oecd2023_pisa2022_ctf_draft,
  author       = "{Organisation for Economic Coâ€‘operation and Development}",
  title        = "{PISA 2022 Creative Thinking Framework (Draft)}",
  year         = "2023",
  howpublished = "\url{https://www.oecd.org/pisa/publications/PISA-2021-creative-thinking-framework.pdf}",
  note         = "Third Draft version of the Creative Thinking Framework for PISA 2022 Innovation Domain (OECD)"
}

@inproceedings{dreambench++,
  title={DreamBench++: A Human-Aligned Benchmark for Personalized Image Generation},
  author={Peng, Yuang and Cui, Yuxin and Tang, Haomiao and Qi, Zekun and Dong, Runpei and Bai, Jing and Han, Chunrui and Ge, Zheng and Zhang, Xiangyu and Xia, Shu-Tao},
  booktitle={The Thirteenth International Conference on Learning Representations}
}

@article{aesbench,
  title={Aesbench: An expert benchmark for multimodal large language models on image aesthetics perception},
  author={Huang, Yipo and Yuan, Quan and Sheng, Xiangfei and Yang, Zhichao and Wu, Haoning and Chen, Pengfei and Yang, Yuzhe and Li, Leida and Lin, Weisi},
  journal={arXiv preprint arXiv:2401.08276},
  year={2024}
}

@inproceedings{lapis,
  title={LAPIS: A novel dataset for personalized image aesthetic assessment},
  author={Maerten, Anne-Sofie and Chen, Li-Wei and De Winter, Stefanie and Bossens, Christophe and Wagemans, Johan},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={6302--6311},
  year={2025}
}

@inproceedings{dalle,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={8821--8831},
  year={2021},
  organization={Pmlr}
}

@inproceedings{stablediffusion,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@inproceedings{styleclip,
  title={Styleclip: Text-driven manipulation of stylegan imagery},
  author={Patashnik, Or and Wu, Zongze and Shechtman, Eli and Cohen-Or, Daniel and Lischinski, Dani},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2085--2094},
  year={2021}
}

@inproceedings{compositional,
  title={Compositional visual generation with composable diffusion models},
  author={Liu, Nan and Li, Shuang and Du, Yilun and Torralba, Antonio and Tenenbaum, Joshua B},
  booktitle={European conference on computer vision},
  pages={423--439},
  year={2022},
  organization={Springer}
}

@inproceedings{instructpix2pix,
  title={Instructpix2pix: Learning to follow image editing instructions},
  author={Brooks, Tim and Holynski, Aleksander and Efros, Alexei A},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={18392--18402},
  year={2023}
}

@article{formaltheory,
  title={Formal theory of creativity, fun, and intrinsic motivation (1990--2010)},
  author={Schmidhuber, J{\"u}rgen},
  journal={IEEE transactions on autonomous mental development},
  volume={2},
  number={3},
  pages={230--247},
  year={2010},
  publisher={Ieee}
}

@article{palme,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and Huang, Wenlong and others},
  year={2023}
}

@inproceedings{hellaswag,
  title={HellaSwag: Can a Machine Really Finish Your Sentence?},
  author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={4791--4800},
  year={2019}
}

@inproceedings{truthfulqa,
  title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={3214--3252},
  year={2022}
}

@software{alpacaeval,
author = {Li, Xuechen and Zhang, Tianyi and Dubois, Yann and Taori, Rohan and Gulrajani, Ishaan and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B.},
month = may,
title = {{AlpacaEval: An Automatic Evaluator of Instruction-following Models}},
year = {2023}
}

@inproceedings{mmbench,
  title={Mmbench: Is your multi-modal model an all-around player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  booktitle={European conference on computer vision},
  pages={216--233},
  year={2024},
  organization={Springer}
}

@inproceedings{mathvista,
  title={MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts},
  author={Lu, Pan and Bansal, Hritik and Xia, Tony and Liu, Jiacheng and Li, Chunyuan and Hajishirzi, Hannaneh and Cheng, Hao and Chang, Kai-Wei and Galley, Michel and Gao, Jianfeng},
  booktitle={The Twelfth International Conference on Learning Representations}
}

@inproceedings{seedbench,
  title={Seed-bench: Benchmarking multimodal large language models},
  author={Li, Bohao and Ge, Yuying and Ge, Yixiao and Wang, Guangzhi and Wang, Rui and Zhang, Ruimao and Shan, Ying},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13299--13308},
  year={2024}
}

@article{pick-a-pic,
  title={Pick-a-pic: An open dataset of user preferences for text-to-image generation},
  author={Kirstain, Yuval and Polyak, Adam and Singer, Uriel and Matiana, Shahbuland and Penna, Joe and Levy, Omer},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={36652--36663},
  year={2023}
}

@inproceedings{ava,
  title={AVA: A large-scale database for aesthetic visual analysis},
  author={Murray, Naila and Marchesotti, Luca and Perronnin, Florent},
  booktitle={2012 IEEE conference on computer vision and pattern recognition},
  pages={2408--2415},
  year={2012},
  organization={IEEE}
}

@article{laion-aesthetic,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}

@inproceedings{chen2024sharegpt4v,
  title={Sharegpt4v: Improving large multi-modal models with better captions},
  author={Chen, Lin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
  booktitle={European Conference on Computer Vision},
  pages={370--387},
  year={2024},
  organization={Springer}
}

@inproceedings{wu2024q,
  title={Q-instruct: Improving low-level visual abilities for multi-modality foundation models},
  author={Wu, Haoning and Zhang, Zicheng and Zhang, Erli and Chen, Chaofeng and Liao, Liang and Wang, Annan and Xu, Kaixin and Li, Chunyi and Hou, Jingwen and Zhai, Guangtao and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={25490--25500},
  year={2024}
}

@inproceedings{sheng2023aesclip,
  title={AesCLIP: Multi-attribute contrastive learning for image aesthetics assessment},
  author={Sheng, Xiangfei and Li, Leida and Chen, Pengfei and Wu, Jinjian and Dong, Weisheng and Yang, Yuzhe and Xu, Liwu and Li, Yaqian and Shi, Guangming},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={1117--1126},
  year={2023}
}

@article{llava,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={34892--34916},
  year={2023}
}




@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PmLR}
}

@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}


@article{t5,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{gpt4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}



@inproceedings{blip2,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}

@article{mplug-owl,
  title={mplug-owl: Modularization empowers large language models with multimodality},
  author={Ye, Qinghao and Xu, Haiyang and Xu, Guohai and Ye, Jiabo and Yan, Ming and Zhou, Yiyang and Wang, Junyang and Hu, Anwen and Shi, Pengcheng and Shi, Yaya and others},
  journal={arXiv preprint arXiv:2304.14178},
  year={2023}
}

@article{otter,
  title={Otter: A multi-modal model with in-context instruction tuning},
  author={Li, Bo and Zhang, Yuanhan and Chen, Liangyu and Wang, Jinghao and Pu, Fanyi and Cahyono, Joshua Adrian and Yang, Jingkang and Li, Chunyuan and Liu, Ziwei},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2025},
  publisher={IEEE}
}

@article{minigpt4,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}

@article{detgpt,
  title={Detgpt: Detect what you need via reasoning},
  author={Pi, Renjie and Gao, Jiahui and Diao, Shizhe and Pan, Rui and Dong, Hanze and Zhang, Jipeng and Yao, Lewei and Han, Jianhua and Xu, Hang and Kong, Lingpeng and others},
  journal={arXiv preprint arXiv:2305.14167},
  year={2023}
}

@inproceedings{lisa,
  title={Lisa: Reasoning segmentation via large language model},
  author={Lai, Xin and Tian, Zhuotao and Chen, Yukang and Li, Yanwei and Yuan, Yuhui and Liu, Shu and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9579--9589},
  year={2024}
}

@inproceedings{gpt4roi,
  title={Gpt4roi: Instruction tuning large language model on region-of-interest},
  author={Zhang, Shilong and Sun, Peize and Chen, Shoufa and Xiao, Min and Shao, Wenqi and Zhang, Wenwei and Liu, Yu and Chen, Kai and Luo, Ping},
  booktitle={European conference on computer vision},
  pages={52--70},
  year={2024},
  organization={Springer}
}

@article{deepseek-vl,
  title={Deepseek-vl: towards real-world vision-language understanding},
  author={Lu, Haoyu and Liu, Wen and Zhang, Bo and Wang, Bingxuan and Dong, Kai and Liu, Bo and Sun, Jingxiang and Ren, Tongzheng and Li, Zhuoshu and Yang, Hao and others},
  journal={arXiv preprint arXiv:2403.05525},
  year={2024}
}

@misc{llavanext,
    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
    month={January},
    year={2024}
}

@inproceedings{yang2022personalized,
  title={Personalized image aesthetics assessment with rich attributes},
  author={Yang, Yuzhe and Xu, Liwu and Li, Leida and Qie, Nan and Li, Yaqian and Zhang, Peng and Guo, Yandong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19861--19869},
  year={2022}
}

@article{runco2012divergent,
  title={Divergent thinking as an indicator of creative potential},
  author={Runco, Mark A and Acar, Selcuk},
  journal={Creativity research journal},
  volume={24},
  number={1},
  pages={66--75},
  year={2012},
  publisher={Taylor \& Francis}
}

@book{creativemind,
  title={The creative mind: Myths and mechanisms},
  author={Boden, Margaret A},
  year={2004},
  publisher={Routledge}
}

@article{standard-of-creativity,
  title={The standard definition of creativity},
  author={Runco, Mark A and Jaeger, Garrett J},
  journal={Creativity research journal},
  volume={24},
  number={1},
  pages={92--96},
  year={2012},
  publisher={Taylor \& Francis}
}

@inproceedings{vqav2,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6904--6913},
  year={2017}
}

@inproceedings{nocaps,
  title={Nocaps: Novel object captioning at scale},
  author={Agrawal, Harsh and Desai, Karan and Wang, Yufei and Chen, Xinlei and Jain, Rishabh and Johnson, Mark and Batra, Dhruv and Parikh, Devi and Lee, Stefan and Anderson, Peter},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8948--8957},
  year={2019}
}

@inproceedings{flickr30k,
  title={Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models},
  author={Plummer, Bryan A and Wang, Liwei and Cervantes, Chris M and Caicedo, Juan C and Hockenmaier, Julia and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2641--2649},
  year={2015}
}

@article{llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{pandagpt,
  title={Pandagpt: One model to instruction-follow them all},
  author={Su, Yixuan and Lan, Tian and Li, Huayang and Xu, Jialu and Wang, Yan and Cai, Deng},
  journal={arXiv preprint arXiv:2305.16355},
  year={2023}
}

@incollection{mumford2013creative,
  title={Creative thinking: Processes, strategies and knowledge},
  author={Mumford, Michael D and Giorgini, Vincent and Gibson, Carter and Mecca, Jensen},
  booktitle={Handbook of research on creativity},
  pages={249--264},
  year={2013},
  publisher={Edward Elgar Publishing}
}

@inproceedings{llava1.5,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={26296--26306},
  year={2024}
}