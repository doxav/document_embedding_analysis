%% Journal article



%Entries
@article{Alpher4,
  author       = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamman and Clark, Jack and others},
  title        = {Learning Transferable Visual Models from Natural Language Supervision},
  journal      = {arXiv preprint arXiv:2103.00020},
  year         = {2021}
}

@inproceedings{TrojanAttack,
  author    = {Liu, Yingqi and Ma, Shiqing and Aafer, Yousra and Lee, Wen-Chuan and Zhai, Juan and Wang, Weihang and Zhang, Xiangyu},
  title     = {Trojaning Attack on Neural Networks},
  booktitle = {Proceedings of the 25th Annual Network and Distributed System Security Symposium (NDSS)},
  year      = {2018}
}

@inproceedings{TrojanNet,
  author    = {Liu, Yingqi and Cheng, Luyao and Lin, Xue and Huang, Wei and Yuan, Bo},
  title     = {TrojanNet: Embedding Hidden Trojan Horse Models within Neural Network},
  booktitle = {Proceedings of the 28th Annual Network and Distributed System Security Symposium (NDSS)},
  year      = {2021}
}

@misc{FastSam,
  author       = {Zhao, Xu and Ding, Wenchao and An, Yongqi and Du, Yinglong and Yu, Tao and Li, Min and Tang, Ming and Wang, Jinqiao},
  title        = {Fast Segment Anything},
  year         = {2023},
  eprint       = {2306.12156},
  archivePrefix= {arXiv},
  primaryClass = {cs.CV},
  url          = {https://arxiv.org/abs/2306.12156}
}

@article{Alpher11,
  author       = {Bansal, H. and Singhi, N. and Yang, Y. and Yin, F. and Grover, A. and Chang, K.-W.},
  title        = {CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning},
  journal      = {arXiv},
  volume       = {abs/2303.03323},
  year         = {2023},
  url          = {http://arxiv.org/abs/2303.03323}
}

@inproceedings{RoCLIP,
  author    = {Yang, W. and Gao, J. and Mirzasoleiman, B.},
  title     = {Robust Contrastive Language-Image Pre-training against Data Poisoning and Backdoor Attacks},
  booktitle = {Proceedings of the 37th Conference on Neural Information Processing Systems (NeurIPS)},
  year      = {2023}
}
@inproceedings{Alpher23,
  author = {J. Zhang and Q. Yi and J. Sang},
  title = {Towards Adversarial Attack on Vision-Language Pre-training Models},
  booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
  pages = {5005--5013},
  year = {2022},
  address = {Lisboa, Portugal},
  publisher = {ACM},
  month = {Oct},
  doi = {10.1145/3503161.3547801}
}

@article{Alpher1,
  author = {B. P. Yuhas and M. H. Goldstein and T. J. Sejnowski},
  title = {Integration of acoustic and visual speech signals using neural networks},
  journal = {IEEE Communications Magazine},
  volume = {27},
  number = {11},
  pages = {65--71},
  year = {1989},
  doi = {10.1109/35.41402}
}

@inproceedings{Alpher2,
  author = {J. Ngiam and A. Khosla and M. Kim and J. Nam and H. Lee and A. Y. Ng},
  title = {Multimodal Deep Learning},
  booktitle = {International Conference on Machine Learning},
  year = {2011}
}

@incollection{Alpher3,
  author       = {Srivastava, N. and Salakhutdinov, R. R.},
  title        = {Multimodal Learning with Deep Boltzmann Machines},
  booktitle    = {Advances in Neural Information Processing Systems},
  editor       = {Pereira, F. and Burges, C. J. and Bottou, L. and Weinberger, K. Q.},
  publisher    = {Curran Associates, Inc.},
  address      = {Red Hook, NY, USA},
  year         = {2012},
  pages        = {2231--2239}
}



@inproceedings{Alpher5,
  author = {C. Jia and Y. Yang and Y. Xia and Y.-T. Chen and Z. Parekh and H. Pham and Q. Le and Y.-H. Sung and Z. Li and T. Duerig},
  title = {Scaling up visual and vision-language representation learning with noisy text supervision},
  booktitle = {International Conference on Machine Learning},
  pages = {4904--4916},
  year = {2021},
  organization = {PMLR}
}

@inproceedings{Alpher6,
  author = {X. Li and X. Yin and C. Li and P. Zhang and X. Hu and L. Zhang and L. Wang and H. Hu and L. Dong and F. Wei and Y. Choi and J. Gao},
  booktitle = {Proceedings of European Conference on Computer Vision},
  title = {Oscar: Object-semantics aligned pre-training for vision-language tasks},
  year = {2020}
}

@article{Alpher7,
  author = {H. Pham and others},
  title = {Combined Scaling for Zero-shot Transfer Learning},
  journal = {arXiv},
  year = {2023},
  volume = {abs/2111.10050},
  doi = {10.48550/arXiv.2111.10050},
  url = {https://arxiv.org/abs/2111.10050}
}

@article{Alpher8,
  author = {A. Radford and others},
  title = {Learning Transferable Visual Models From Natural Language Supervision},
  journal = {arXiv},
  year = {2021},
  volume = {abs/2103.00020},
  url = {http://arxiv.org/abs/2103.00020}
}


@inproceedings{Alpher9,
  author = {B. Biggio and B. Nelson and P. Laskov},
  title = {Poisoning attacks against support vector machines},
  booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
  series = {ICML'12},
  publisher = {Omnipress},
  address = {Madison, WI, USA},
  month = {Jun},
  year = {2012},
  pages = {1467--1474}
}



@inproceedings{Alpher12,
  author = {P. Sharma and N. Ding and S. Goodman and R. Soricut},
  title = {Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset for Automatic Image Captioning},
  booktitle = {Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL)},
  year = {2018}
}

@inproceedings{Alpher13,
  author = {Y. Li and F. Liang and L. Zhao and Y. Cui and W. Ouyang and J. Shao and F. Yu and J. Yan},
  title = {Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm},
  booktitle = {International Conference on Learning Representations},
  year = {2022}
}

@inproceedings{Alpher14,
  author = {S. Goel and H. Bansal and S. Bhatia and R. A. Rossi and V. Vinay and A. Grover},
  title = {CyCLIP: Cyclic Contrastive Language-Image Pretraining},
  editor = {A. H. Oh and A. Agarwal and D. Belgrave and K. Cho},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2022}
}

@inproceedings{Alpher15,
  author = {N. Carlini and A. Terzis},
  title = {Poisoning and Backdooring Contrastive Learning},
  booktitle = {International Conference on Learning Representations},
  year = {2022}
}

@article{Alpher16,
  author = {T. Gu and B. Dolan-Gavitt and S. Garg},
  title = {Badnets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain},
  journal = {arXiv preprint arXiv:1708.06733},
  year = {2017}
}

@inproceedings{Alpher17,
  author = {T. A. Nguyen and A. T. Tran},
  title = {Wanet - Imperceptible Warping-based Backdoor Attack},
  booktitle = {International Conference on Learning Representations},
  year = {2021}
}

@article{Alpher18,
  author = {A. Kirillov and others},
  title = {Segment Anything},
  journal = {arXiv},
  year = {2023},
  volume = {abs/2304.02643},
  doi = {10.48550/arXiv.2304.02643},
  url = {https://arxiv.org/abs/2304.02643}
}

@article{Alpher19,
  author = {P. Young and A. Lai and M. Hodosh and J. Hockenmaier},
  title = {From Image Descriptions to Visual Denotations: New Similarity Metrics for Semantic Inference Over Event Descriptions},
  journal = {Transactions of the Association for Computational Linguistics (TACL)},
  volume = {2},
  pages = {67--78},
  month = {Dec},
  year = {2014}
}

@inproceedings{Alpher20,
  author = {Ekin D Cubuk and Barret Zoph and Dandelion Mane and Vijay Vasudevan and Quoc V Le},
  title = {AutoAugment: Learning Augmentation Strategies from Data},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year = {2019}
}


@inproceedings{Alpher21,
  author = {Jason Wei and Kai Zou},
  title = {EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks},
  booktitle = {Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL)},
  year = {2019}
}

@misc{Alpher10,
      title={Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision}, 
      author={Chao Jia and Yinfei Yang and Ye Xia and Yi-Ting Chen and Zarana Parekh and Hieu Pham and Quoc V. Le and Yunhsuan Sung and Zhen Li and Tom Duerig},
      year={2021},
      eprint={2102.05918},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Alpher22,
  author = {Hieu Pham and Zihang Dai and Golnaz Ghiasi and Kenji Kawaguchi and Hanxiao Liu and Adams Wei Yu and Jiahui Yu and Yi-Ting Chen and Minh-Thang Luong and Yonghui Wu and others},
  title = {Combined Scaling for Open-Vocabulary Image Classification},
  journal = {arXiv preprint arXiv:2111.10050},
  year = {2021}
}



@INPROCEEDINGS{Alpher24,
  author={Di Ruberto, C. and Rodriguez, G. and Vitulano, S.},
  booktitle={Proceedings 10th International Conference on Image Analysis and Processing}, 
  title={Image segmentation by texture analysis}, 
  year={1999},
  volume={},
  number={},
  pages={376-381},
  doi={10.1109/ICIAP.1999.797624}}

@misc{Alpher26,
      title={Segment Anything}, 
      author={Alexander Kirillov and Eric Mintun and Nikhila Ravi and Hanzi Mao and Chloe Rolland and Laura Gustafson and Tete Xiao and Spencer Whitehead and Alexander C. Berg and Wan-Yen Lo and Piotr Dollár and Ross Girshick},
      year={2023},
      eprint={2304.02643},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Alpher25,
  author = {P. F. Felzenszwalb and D. P. Huttenlocher},
  title = {Efficient Graph-Based Image Segmentation},
  journal = {International Journal of Computer Vision},
  volume = {59},
  number = {2},
  pages = {167--181},
  year = {2004},
  month = {Sep},
  doi = {10.1023/B:VISI.0000022288.19776.77}
}




@misc{Alpher27,
      title={Towards Adversarial Attack on Vision-Language Pre-training Models}, 
      author={Jiaming Zhang and Qi Yi and Jitao Sang},
      year={2022},
      eprint={2206.09391},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{Alpher28,
  author = {Jia Deng and Wei Dong and Richard Socher and Li-Jia Li and Kai Li and Li Fei-Fei},
  title = {ImageNet: A Large-Scale Hierarchical Image Database},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages = {248--255},
  year = {2009},
  address = {Miami, FL, USA},
  publisher = {IEEE},
  month = {Jun},
  doi = {10.1109/CVPR.2009.5206848}
}

@article{Alpher29,
  author       = {Krizhevsky, Alex and Nair, Vinod and Hinton, Geoffrey},
  title        = {CIFAR-10: A Dataset for Image Recognition and Machine Learning},
  journal      = {Canadian Institute for Advanced Research (CIFAR)},
  year         = {2009},
  url          = {https://www.cs.toronto.edu/~kriz/cifar.html}
}

@ARTICLE{VLM1,
  author={Zhang, Jingyi and Huang, Jiaxing and Jin, Sheng and Lu, Shijian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Vision-Language Models for Vision Tasks: A Survey}, 
  year={2024},
  volume={46},
  number={8},
  pages={5625-5644},
  keywords={Task analysis;Visualization;Training;Deep learning;Surveys;Data models;Predictive models;Big Data;big model;deep learning;deep neural network;knowledge distillation;object detection;pre-training;semantic segmentation;transfer learning;vision-language model;visual recognition;image classification},
  doi={10.1109/TPAMI.2024.3369699}
}

@misc{VLM2,
      title={What matters when building vision-language models?}, 
      author={Hugo Laurençon and Léo Tronchon and Matthieu Cord and Victor Sanh},
      year={2024},
      eprint={2405.02246},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.02246}, 
}

@misc{VLM3,
      title={An Introduction to Vision-Language Modeling}, 
      author={Florian Bordes and Richard Yuanzhe Pang and Anurag Ajay and Alexander C. Li and Adrien Bardes and Suzanne Petryk and Oscar Mañas and Zhiqiu Lin and Anas Mahmoud and Bargav Jayaraman and Mark Ibrahim and Melissa Hall and Yunyang Xiong and Jonathan Lebensold and Candace Ross and Srihari Jayakumar and Chuan Guo and Diane Bouchacourt and Haider Al-Tahan and Karthik Padthe and Vasu Sharma and Hu Xu and Xiaoqing Ellen Tan and Megan Richards and Samuel Lavoie and Pietro Astolfi and Reyhane Askari Hemmat and Jun Chen and Kushal Tirumala and Rim Assouel and Mazda Moayeri and Arjang Talattof and Kamalika Chaudhuri and Zechun Liu and Xilun Chen and Quentin Garrido and Karen Ullrich and Aishwarya Agrawal and Kate Saenko and Asli Celikyilmaz and Vikas Chandra},
      year={2024},
      eprint={2405.17247},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.17247}, 
}

@misc{VLM4,
      title={Vision-Language Models as Success Detectors}, 
      author={Yuqing Du and Ksenia Konyushkova and Misha Denil and Akhil Raju and Jessica Landon and Felix Hill and Nando de Freitas and Serkan Cabi},
      year={2023},
      eprint={2303.07280},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2303.07280}, 
}

@misc{FLIP,
      title={Scaling Language-Image Pre-training via Masking}, 
      author={Yanghao Li and Haoqi Fan and Ronghang Hu and Christoph Feichtenhofer and Kaiming He},
      year={2023},
      eprint={2212.00794},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.00794}, 
}

@misc{BLIP,
      title={BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation}, 
      author={Junnan Li and Dongxu Li and Caiming Xiong and Steven Hoi},
      year={2022},
      eprint={2201.12086},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2201.12086}, 
}

@misc{backdoorattack1,
      title={Backdoor Attacks and Countermeasures on Deep Learning: A Comprehensive Review}, 
      author={Yansong Gao and Bao Gia Doan and Zhi Zhang and Siqi Ma and Jiliang Zhang and Anmin Fu and Surya Nepal and Hyoungshick Kim},
      year={2020},
      eprint={2007.10760},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2007.10760}, 
}

@inproceedings{backdoorattack2,
 author = {Doan, Khoa and Lao, Yingjie and Li, Ping},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {18944--18957},
 publisher = {Curran Associates, Inc.},
 title = {Backdoor Attack with Imperceptible Input and Latent Modification},
 volume = {34},
 year = {2021}
}


@InProceedings{backdoorattack3,
  title = 	 {Rethinking Backdoor Attacks},
  author =       {Khaddaj, Alaa and Leclerc, Guillaume and Makelov, Aleksandar and Georgiev, Kristian and Salman, Hadi and Ilyas, Andrew and Madry, Aleksander},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {16216--16236},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/khaddaj23a/khaddaj23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/khaddaj23a.html},
  abstract = 	 {In a <em>backdoor attack</em>, an adversary inserts maliciously constructed backdoor examples into a training set to make the resulting model vulnerable to manipulation. Defending against such attacks involves viewing inserted examples as outliers in the training set and using techniques from robust statistics to detect and remove them. In this work, we present a different approach to the backdoor attack problem. Specifically, we show that without structural information about the training data distribution, backdoor attacks are <em>indistinguishable</em> from naturally-occuring features in the data—and thus impossible to "detect" in a general sense. Then, guided by this observation, we revisit existing defenses against backdoor attacks and characterize the (often latent) assumptions they make, and on which they depend. Finally, we explore an alternative perspective on backdoor attacks: one that assumes these attacks correspond to the <em>strongest</em> feature in the training data. Under this assumption (which we make formal) we develop a new primitive for detecting backdoor attacks. Our primitive naturally gives rise to a detection algorithm that comes with theoretical guarantees, and is effective in practice.}
}

@misc{trigger,
      title={Rethinking the Trigger of Backdoor Attack}, 
      author={Yiming Li and Tongqing Zhai and Baoyuan Wu and Yong Jiang and Zhifeng Li and Shutao Xia},
      year={2021},
      eprint={2004.04692},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2004.04692}, 
}

@article{segmentation,
title = {A new method for image segmentation},
journal = {Computer Vision, Graphics, and Image Processing},
volume = {46},
number = {1},
pages = {82-95},
year = {1989},
issn = {0734-189X},
doi = {https://doi.org/10.1016/S0734-189X(89)80017-9},
url = {https://www.sciencedirect.com/science/article/pii/S0734189X89800179},
author = {S.D. Yanowitz and A.M. Bruckstein},
abstract = {In applications involving visual inspection, it is often required to separate objects from background, in conditions of poor and nonuniform illumination. In such cases one has to rely on adaptive methods that learn the illumination from the given images and base the object/background decision on this information. We here present a new method for image segmentation via adaptive thresholding. The threshold surface is determined by interpolating the image gray levels at points where the gradient is high, indicating probable object edges. Several methods of data interpolation to levels given at scattered points in the image plane are discussed. One method is tested on several examples and the segmentation results are compared to previously proposed adaptive thresholding algorithms.}
}

@misc{multimodal_learning1,
      title={Multimodal Contrastive Training for Visual Representation Learning}, 
      author={Xin Yuan and Zhe Lin and Jason Kuen and Jianming Zhang and Yilin Wang and Michael Maire and Ajinkya Kale and Baldo Faieta},
      year={2021},
      eprint={2104.12836},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2104.12836}, 
}

@misc{contrastive_learning1,
      title={A Simple Framework for Contrastive Learning of Visual Representations}, 
      author={Ting Chen and Simon Kornblith and Mohammad Norouzi and Geoffrey Hinton},
      year={2020},
      eprint={2002.05709},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2002.05709}, 
}

@inbook{Generalization1,
   title={Generalization in Deep Learning},
   ISBN={9781316516782},
   url={http://dx.doi.org/10.1017/9781009025096.003},
   DOI={10.1017/9781009025096.003},
   booktitle={Mathematical Aspects of Deep Learning},
   publisher={Cambridge University Press},
   author={Kawaguchi, K. and Bengio, Y. and Kaelbling, L.},
   year={2022},
   month=dec, pages={112–148} }

@article{finetune1,
   title={A local basis approximation approach for nonlinear parametric model order reduction},
   volume={502},
   ISSN={0022-460X},
   url={http://dx.doi.org/10.1016/j.jsv.2021.116055},
   DOI={10.1016/j.jsv.2021.116055},
   journal={Journal of Sound and Vibration},
   publisher={Elsevier BV},
   author={Vlachas, Konstantinos and Tatsis, Konstantinos and Agathos, Konstantinos and Brink, Adam R. and Chatzi, Eleni},
   year={2021},
   month=jun, pages={116055} }

@article{regularization1,
title = {A comprehensive survey on regularization strategies in machine learning},
journal = {Information Fusion},
volume = {80},
pages = {146-166},
year = {2022},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2021.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S156625352100230X},
author = {Yingjie Tian and Yuqi Zhang},
keywords = {Overfitting, Generalization, Regularization, Machine learning},
abstract = {In machine learning, the model is not as complicated as possible. Good generalization ability means that the model not only performs well on the training data set, but also can make good prediction on new data. Regularization imposes a penalty on model’s complexity or smoothness, allowing for good generalization to unseen data even when training on a finite training set or with an inadequate iteration. Deep learning has developed rapidly in recent years. Then the regularization has a broader definition: regularization is a technology aimed at improving the generalization ability of a model. This paper gave a comprehensive study and a state-of-the-art review of the regularization strategies in machine learning. Then the characteristics and comparisons of regularizations were presented. In addition, it discussed how to choose a regularization for the specific task. For specific tasks, it is necessary for regularization technology to have good mathematical characteristics. Meanwhile, new regularization techniques can be constructed by extending and combining existing regularization techniques. Finally, it concluded current opportunities and challenges of regularization technologies, as well as many open concerns and research trends.}
}

@misc{Resnet,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1512.03385}, 
}

@misc{Transformer1,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@misc{ViT,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

@misc{AdamW,
      title={Decoupled Weight Decay Regularization}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2019},
      eprint={1711.05101},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1711.05101}, 
}

@article{ASR,
  title={Explaining and Harnessing Adversarial Examples},
  author={Ian Goodfellow and Jonathon Shlens and Christian Szegedy},
  journal={arXiv preprint arXiv:1412.6572},
  year={2015}
}